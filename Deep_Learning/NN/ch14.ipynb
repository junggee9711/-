{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b2487bc06f72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 raise ValueError('Layer ' + self.name + ' was called with '\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m    697\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TensorLike\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.compat.v1.placeholder(dtype=tf.float32, shape=(None), name='x')\n",
    "    w = tf.Variable(2.0, name='weight')\n",
    "    b = tf.Variable(0.7, name='bias')\n",
    "    \n",
    "    z = w*x + b\n",
    "    \n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    ## w와 b를 초기화합니다.\n",
    "    sess.run(init)\n",
    "    ## z를 평가합니다.\n",
    "    for t in [1.0, 0.6, -1.8]:\n",
    "        print('x=%4.1f --> z=%4.1f'%(\n",
    "              t, sess.run(z, feed_dict={x:t})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= 1.0 --> z= 2.7\n",
      "x= 0.6 --> z= 1.9\n",
      "x=-1.8 --> z=-2.9\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(2.0, name='weight')\n",
    "b = tf.Variable(0.7, name='bias')\n",
    "\n",
    "# z를 평가합니다.\n",
    "for x in [1.0, 0.6, -1.8]:\n",
    "    z = w * x + b\n",
    "    print('x=%4.1f --> z=%4.1f' %(x, z))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 () (4,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "t1 = tf.constant(np.pi)\n",
    "t2 = tf.constant([1,2,3,4])\n",
    "t3 = tf.constant([[1,2],[3,4]])\n",
    "\n",
    "r1 = tf.rank(t1)\n",
    "r2 = tf.rank(t2)\n",
    "r3 = tf.rank(t3)\n",
    "\n",
    "s1 = t1.get_shape()\n",
    "s2 = t2.get_shape()\n",
    "s3 = t3.get_shape()\n",
    "\n",
    "print(r1.numpy(), r2.numpy(), r3.numpy(), s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.  2.  3.  3.5]\n",
      " [4.  5.  6.  6.5]\n",
      " [7.  8.  9.  9.5]], shape=(3, 4), dtype=float64)\n",
      "(3, 4)\n",
      "(3, 4)\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64, numpy=\n",
      "array([[-1.09793426,  0.72202649,  1.73717949,  0.30492175],\n",
      "       [-1.75069169,  1.61588991,  0.51973261,  0.14848238],\n",
      "       [-0.26572042, -1.49991679, -1.7284678 ,  0.82598001]])>\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float64, numpy=array([ 0.56656373, -0.57511607,  0.10482668])>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1.,2.,3.,3.5],\n",
    "                [4.,5.,6.,6.5],\n",
    "                [7.,8.,9.,9.5]])\n",
    "T1 = tf.constant(arr)\n",
    "print(T1)\n",
    "s = T1.get_shape()\n",
    "print(s)\n",
    "print(T1.shape)\n",
    "T2 = tf.Variable(np.random.normal(size=s))\n",
    "T3 = tf.Variable(np.random.normal(size=s[0]))\n",
    "print(T2)\n",
    "print(T3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]], shape=(1, 3, 4), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[1. ]\n",
      "  [4. ]\n",
      "  [7. ]]\n",
      "\n",
      " [[2. ]\n",
      "  [5. ]\n",
      "  [8. ]]\n",
      "\n",
      " [[3. ]\n",
      "  [6. ]\n",
      "  [9. ]]\n",
      "\n",
      " [[3.5]\n",
      "  [6.5]\n",
      "  [9.5]]], shape=(4, 3, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "T5 = tf.reshape(T1, shape=[1,3,-1])\n",
    "print(T5)\n",
    "T6 = tf.transpose(T5, [2,1,0])\n",
    "print(T6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[1., 2.],\n",
      "        [4., 5.],\n",
      "        [7., 8.]]])>, <tf.Tensor: shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[3. , 3.5],\n",
      "        [6. , 6.5],\n",
      "        [9. , 9.5]]])>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T5_split = tf.split(T5, num_or_size_splits = 2, axis = 2)\n",
    "print(T5_split)\n",
    "tf.Variable(1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "844/844 [==============================] - 1s 648us/step - loss: 1.1506 - val_loss: 0.3659\n",
      "Epoch 2/50\n",
      "844/844 [==============================] - 0s 485us/step - loss: 0.3980 - val_loss: 0.2749\n",
      "Epoch 3/50\n",
      "844/844 [==============================] - 0s 474us/step - loss: 0.3132 - val_loss: 0.2370\n",
      "Epoch 4/50\n",
      "844/844 [==============================] - 0s 476us/step - loss: 0.2690 - val_loss: 0.2142\n",
      "Epoch 5/50\n",
      "844/844 [==============================] - 0s 477us/step - loss: 0.2381 - val_loss: 0.1975\n",
      "Epoch 6/50\n",
      "844/844 [==============================] - 0s 484us/step - loss: 0.2216 - val_loss: 0.1845\n",
      "Epoch 7/50\n",
      "844/844 [==============================] - 0s 484us/step - loss: 0.2088 - val_loss: 0.1736\n",
      "Epoch 8/50\n",
      "844/844 [==============================] - 0s 487us/step - loss: 0.1889 - val_loss: 0.1656\n",
      "Epoch 9/50\n",
      "844/844 [==============================] - 0s 482us/step - loss: 0.1838 - val_loss: 0.1583\n",
      "Epoch 10/50\n",
      "844/844 [==============================] - 0s 479us/step - loss: 0.1670 - val_loss: 0.1524\n",
      "Epoch 11/50\n",
      "844/844 [==============================] - 0s 482us/step - loss: 0.1617 - val_loss: 0.1478\n",
      "Epoch 12/50\n",
      "844/844 [==============================] - 0s 481us/step - loss: 0.1537 - val_loss: 0.1430\n",
      "Epoch 13/50\n",
      "844/844 [==============================] - 0s 478us/step - loss: 0.1455 - val_loss: 0.1405\n",
      "Epoch 14/50\n",
      "844/844 [==============================] - 0s 482us/step - loss: 0.1362 - val_loss: 0.1369\n",
      "Epoch 15/50\n",
      "844/844 [==============================] - 0s 482us/step - loss: 0.1295 - val_loss: 0.1333\n",
      "Epoch 16/50\n",
      "844/844 [==============================] - 0s 501us/step - loss: 0.1266 - val_loss: 0.1312\n",
      "Epoch 17/50\n",
      "844/844 [==============================] - 0s 475us/step - loss: 0.1240 - val_loss: 0.1285\n",
      "Epoch 18/50\n",
      "844/844 [==============================] - 0s 479us/step - loss: 0.1174 - val_loss: 0.1265\n",
      "Epoch 19/50\n",
      "844/844 [==============================] - 0s 482us/step - loss: 0.1118 - val_loss: 0.1252\n",
      "Epoch 20/50\n",
      "844/844 [==============================] - 0s 481us/step - loss: 0.1073 - val_loss: 0.1237\n",
      "Epoch 21/50\n",
      "844/844 [==============================] - 0s 480us/step - loss: 0.1021 - val_loss: 0.1223\n",
      "Epoch 22/50\n",
      "844/844 [==============================] - 0s 475us/step - loss: 0.0989 - val_loss: 0.1213\n",
      "Epoch 23/50\n",
      "844/844 [==============================] - 0s 481us/step - loss: 0.0952 - val_loss: 0.1207\n",
      "Epoch 24/50\n",
      "844/844 [==============================] - 0s 482us/step - loss: 0.0935 - val_loss: 0.1184\n",
      "Epoch 25/50\n",
      "844/844 [==============================] - 0s 478us/step - loss: 0.0866 - val_loss: 0.1188\n",
      "Epoch 26/50\n",
      "844/844 [==============================] - 0s 483us/step - loss: 0.0885 - val_loss: 0.1179\n",
      "Epoch 27/50\n",
      "844/844 [==============================] - 0s 483us/step - loss: 0.0855 - val_loss: 0.1168\n",
      "Epoch 28/50\n",
      "844/844 [==============================] - 0s 477us/step - loss: 0.0816 - val_loss: 0.1157\n",
      "Epoch 29/50\n",
      "844/844 [==============================] - 0s 476us/step - loss: 0.0788 - val_loss: 0.1151\n",
      "Epoch 30/50\n",
      "844/844 [==============================] - 0s 481us/step - loss: 0.0770 - val_loss: 0.1155\n",
      "Epoch 31/50\n",
      "844/844 [==============================] - 0s 480us/step - loss: 0.0735 - val_loss: 0.1145\n",
      "Epoch 32/50\n",
      "844/844 [==============================] - 0s 481us/step - loss: 0.0711 - val_loss: 0.1146\n",
      "Epoch 33/50\n",
      "844/844 [==============================] - 0s 480us/step - loss: 0.0684 - val_loss: 0.1141\n",
      "Epoch 34/50\n",
      "844/844 [==============================] - 0s 479us/step - loss: 0.0644 - val_loss: 0.1141\n",
      "Epoch 35/50\n",
      "844/844 [==============================] - 0s 473us/step - loss: 0.0636 - val_loss: 0.1140\n",
      "Epoch 36/50\n",
      "844/844 [==============================] - 0s 475us/step - loss: 0.0647 - val_loss: 0.1133\n",
      "Epoch 37/50\n",
      "844/844 [==============================] - 0s 488us/step - loss: 0.0603 - val_loss: 0.1132\n",
      "Epoch 38/50\n",
      "844/844 [==============================] - 0s 479us/step - loss: 0.0568 - val_loss: 0.1127\n",
      "Epoch 39/50\n",
      "844/844 [==============================] - 0s 481us/step - loss: 0.0574 - val_loss: 0.1131\n",
      "Epoch 40/50\n",
      "844/844 [==============================] - 0s 476us/step - loss: 0.0563 - val_loss: 0.1125\n",
      "Epoch 41/50\n",
      "844/844 [==============================] - 0s 489us/step - loss: 0.0561 - val_loss: 0.1135\n",
      "Epoch 42/50\n",
      "844/844 [==============================] - 0s 481us/step - loss: 0.0546 - val_loss: 0.1127\n",
      "Epoch 43/50\n",
      "844/844 [==============================] - 0s 499us/step - loss: 0.0526 - val_loss: 0.1123\n",
      "Epoch 44/50\n",
      "844/844 [==============================] - 0s 480us/step - loss: 0.0495 - val_loss: 0.1129\n",
      "Epoch 45/50\n",
      "844/844 [==============================] - 0s 479us/step - loss: 0.0498 - val_loss: 0.1129\n",
      "Epoch 46/50\n",
      "844/844 [==============================] - 0s 478us/step - loss: 0.0461 - val_loss: 0.1128\n",
      "Epoch 47/50\n",
      "844/844 [==============================] - 0s 482us/step - loss: 0.0466 - val_loss: 0.1126\n",
      "Epoch 48/50\n",
      "844/844 [==============================] - 0s 483us/step - loss: 0.0438 - val_loss: 0.1128\n",
      "Epoch 49/50\n",
      "844/844 [==============================] - 0s 484us/step - loss: 0.0466 - val_loss: 0.1132\n",
      "Epoch 50/50\n",
      "844/844 [==============================] - 0s 488us/step - loss: 0.0432 - val_loss: 0.1134\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(X_train_un, y_train), (X_test_un, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train_un.reshape(60000, -1)\n",
    "X_test = X_test_un.reshape(10000, -1)\n",
    "\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val\n",
    "\n",
    "del X_train, X_test\n",
    "np.random.seed(123)\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "tf.keras.layers.Dense(\n",
    "    units=50,\n",
    "    input_dim=X_train_centered.shape[1],\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zero',\n",
    "    activation='tanh'))\n",
    "\n",
    "model.add(\n",
    "tf.keras.layers.Dense(\n",
    "    units=50,\n",
    "    input_dim=50,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zero',\n",
    "    activation='tanh'))\n",
    "\n",
    "model.add(\n",
    "tf.keras.layers.Dense(\n",
    "    units=y_train_onehot.shape[1],\n",
    "    input_dim=50,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zero',\n",
    "    activation='softmax'))\n",
    "\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr = 0.001, decay = 1e-7, momentum=.9)\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy')\n",
    "history = model.fit(X_train_centered, y_train_onehot, batch_size=64, epochs=50, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csle/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "print(y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9621\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)\n",
    "\n",
    "train_acc = correct_preds/y_train.shape[0]\n",
    "y_test_pred = model.predict_classes(X_test_centered, verbose=0)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)\n",
    "\n",
    "train_acc = correct_preds/y_test.shape[0]\n",
    "\n",
    "print(train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=2, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0, scale=(0.5+t*t/3), size=None)\n",
    "        y.append(r)\n",
    "    return x, 1.726*x-0.84+np.array(y)\n",
    "\n",
    "x, y = make_random_data()\n",
    "\n",
    "plt.plot(x,y,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6974 - val_loss: 1.3652\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.6654 - val_loss: 1.2761\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4492 - val_loss: 1.1978\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3951 - val_loss: 1.1381\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2359 - val_loss: 1.0839\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3198 - val_loss: 1.0432\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0333 - val_loss: 1.0073\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0060 - val_loss: 0.9831\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0142 - val_loss: 0.9635\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8665 - val_loss: 0.9385\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8688 - val_loss: 0.9220\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0030 - val_loss: 0.9103\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9258 - val_loss: 0.9026\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7920 - val_loss: 0.8925\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0076 - val_loss: 0.8852\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9083 - val_loss: 0.8804\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9651 - val_loss: 0.8761\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8291 - val_loss: 0.8739\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7690 - val_loss: 0.8727\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7915 - val_loss: 0.8731\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8614 - val_loss: 0.8711\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7567 - val_loss: 0.8719\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7824 - val_loss: 0.8725\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8010 - val_loss: 0.8713\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8337 - val_loss: 0.8724\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8179 - val_loss: 0.8714\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7739 - val_loss: 0.8720\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6616 - val_loss: 0.8727\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8559 - val_loss: 0.8725\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7127 - val_loss: 0.8754\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7593 - val_loss: 0.8767\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8541 - val_loss: 0.8795\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7022 - val_loss: 0.8846\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7101 - val_loss: 0.8864\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7906 - val_loss: 0.8906\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6802 - val_loss: 0.8901\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8106 - val_loss: 0.8906\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8133 - val_loss: 0.8896\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7767 - val_loss: 0.8896\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7423 - val_loss: 0.8900\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7353 - val_loss: 0.8967\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8003 - val_loss: 0.8993\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7891 - val_loss: 0.9004\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7235 - val_loss: 0.9034\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8255 - val_loss: 0.9061\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7631 - val_loss: 0.9025\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7355 - val_loss: 0.9004\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7895 - val_loss: 0.9008\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6882 - val_loss: 0.9048\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7055 - val_loss: 0.9022\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8185 - val_loss: 0.9015\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7863 - val_loss: 0.9029\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7012 - val_loss: 0.9029\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6964 - val_loss: 0.9014\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8015 - val_loss: 0.8993\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7754 - val_loss: 0.8948\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7522 - val_loss: 0.8931\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7551 - val_loss: 0.8920\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6845 - val_loss: 0.8933\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6870 - val_loss: 0.8919\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7549 - val_loss: 0.8917\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7933 - val_loss: 0.8948\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7929 - val_loss: 0.8951\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7993 - val_loss: 0.8942\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6737 - val_loss: 0.8980\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8206 - val_loss: 0.8990\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7905 - val_loss: 0.9001\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7170 - val_loss: 0.9017\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7459 - val_loss: 0.9025\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6782 - val_loss: 0.9016\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7587 - val_loss: 0.8988\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7417 - val_loss: 0.9014\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7029 - val_loss: 0.9073\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7949 - val_loss: 0.9073\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7197 - val_loss: 0.9056\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6777 - val_loss: 0.9063\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8385 - val_loss: 0.9073\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7376 - val_loss: 0.9067\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7241 - val_loss: 0.9026\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7434 - val_loss: 0.8996\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6370 - val_loss: 0.9007\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7712 - val_loss: 0.9011\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8194 - val_loss: 0.9038\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7091 - val_loss: 0.9033\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7637 - val_loss: 0.9108\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7605 - val_loss: 0.9055\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6979 - val_loss: 0.9034\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6956 - val_loss: 0.9016\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7299 - val_loss: 0.8984\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7276 - val_loss: 0.9038\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8372 - val_loss: 0.9042\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7455 - val_loss: 0.9027\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7064 - val_loss: 0.9023\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6642 - val_loss: 0.9050\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7653 - val_loss: 0.9058\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7097 - val_loss: 0.8999\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.9009\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7384 - val_loss: 0.9019\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7823 - val_loss: 0.9058\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7612 - val_loss: 0.9046\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7843 - val_loss: 0.9082\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6843 - val_loss: 0.9070\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7844 - val_loss: 0.9071\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6874 - val_loss: 0.9073\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7584 - val_loss: 0.9073\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7445 - val_loss: 0.9075\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7428 - val_loss: 0.9158\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8100 - val_loss: 0.9105\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7298 - val_loss: 0.9104\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6948 - val_loss: 0.9083\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7849 - val_loss: 0.9050\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6747 - val_loss: 0.9058\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7995 - val_loss: 0.9087\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8702 - val_loss: 0.9071\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6887 - val_loss: 0.9012\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7367 - val_loss: 0.8967\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6723 - val_loss: 0.8976\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7093 - val_loss: 0.8964\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6996 - val_loss: 0.8986\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8406 - val_loss: 0.8973\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8058 - val_loss: 0.8975\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7868 - val_loss: 0.8964\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8125 - val_loss: 0.8964\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7198 - val_loss: 0.8984\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7514 - val_loss: 0.8981\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8339 - val_loss: 0.9001\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8081 - val_loss: 0.8994\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7596 - val_loss: 0.8996\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7615 - val_loss: 0.8985\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7849 - val_loss: 0.9010\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6682 - val_loss: 0.9024\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7212 - val_loss: 0.9008\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7355 - val_loss: 0.8993\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6984 - val_loss: 0.9006\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7365 - val_loss: 0.9025\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8183 - val_loss: 0.9000\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7276 - val_loss: 0.8982\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8378 - val_loss: 0.9027\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8813 - val_loss: 0.9018\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8301 - val_loss: 0.9049\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6548 - val_loss: 0.8987\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7448 - val_loss: 0.9002\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7478 - val_loss: 0.9049\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7428 - val_loss: 0.9098\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8198 - val_loss: 0.9088\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6929 - val_loss: 0.9048\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7943 - val_loss: 0.9036\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8701 - val_loss: 0.9033\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8706 - val_loss: 0.9018\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7694 - val_loss: 0.9016\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6533 - val_loss: 0.8981\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7760 - val_loss: 0.8938\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6988 - val_loss: 0.8995\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7278 - val_loss: 0.8992\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7481 - val_loss: 0.9034\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7331 - val_loss: 0.9036\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6913 - val_loss: 0.9034\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8721 - val_loss: 0.9035\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7087 - val_loss: 0.9026\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8443 - val_loss: 0.9032\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6916 - val_loss: 0.9001\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7731 - val_loss: 0.9005\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8406 - val_loss: 0.8985\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7103 - val_loss: 0.9009\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7734 - val_loss: 0.9032\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7424 - val_loss: 0.9036\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6875 - val_loss: 0.8997\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7222 - val_loss: 0.9051\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7863 - val_loss: 0.9073\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6979 - val_loss: 0.9073\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7732 - val_loss: 0.9050\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8346 - val_loss: 0.9048\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7254 - val_loss: 0.9037\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8573 - val_loss: 0.9024\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7595 - val_loss: 0.9016\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7616 - val_loss: 0.8999\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6706 - val_loss: 0.9014\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7828 - val_loss: 0.9002\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7107 - val_loss: 0.8972\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7630 - val_loss: 0.8991\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7287 - val_loss: 0.9004\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8205 - val_loss: 0.8980\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6873 - val_loss: 0.8987\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6788 - val_loss: 0.8973\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7556 - val_loss: 0.8956\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7213 - val_loss: 0.8998\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7747 - val_loss: 0.9004\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7436 - val_loss: 0.9038\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6865 - val_loss: 0.9037\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6690 - val_loss: 0.9073\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6412 - val_loss: 0.9095\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7891 - val_loss: 0.9063\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6887 - val_loss: 0.9011\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7007 - val_loss: 0.9037\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7349 - val_loss: 0.9075\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7599 - val_loss: 0.9093\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7027 - val_loss: 0.9087\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7752 - val_loss: 0.9080\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7804 - val_loss: 0.9060\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8647 - val_loss: 0.9048\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6477 - val_loss: 0.9023\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7583 - val_loss: 0.9017\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8208 - val_loss: 0.9010\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7252 - val_loss: 0.9025\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7284 - val_loss: 0.9045\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8439 - val_loss: 0.9027\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7013 - val_loss: 0.9108\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7745 - val_loss: 0.9088\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8276 - val_loss: 0.9076\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7590 - val_loss: 0.9093\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7515 - val_loss: 0.9169\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7589 - val_loss: 0.9133\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8384 - val_loss: 0.9120\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7247 - val_loss: 0.9174\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7577 - val_loss: 0.9200\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7684 - val_loss: 0.9167\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8281 - val_loss: 0.9141\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7981 - val_loss: 0.9138\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7954 - val_loss: 0.9136\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7455 - val_loss: 0.9206\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7402 - val_loss: 0.9205\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8137 - val_loss: 0.9187\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7763 - val_loss: 0.9123\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7372 - val_loss: 0.9118\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7173 - val_loss: 0.9121\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7618 - val_loss: 0.9129\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7074 - val_loss: 0.9093\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7502 - val_loss: 0.9039\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6960 - val_loss: 0.9087\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6812 - val_loss: 0.9081\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7863 - val_loss: 0.9076\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7007 - val_loss: 0.9075\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7558 - val_loss: 0.9071\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7225 - val_loss: 0.9060\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7570 - val_loss: 0.9061\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7513 - val_loss: 0.9038\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6872 - val_loss: 0.9014\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7435 - val_loss: 0.8998\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8018 - val_loss: 0.8967\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7787 - val_loss: 0.8954\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7210 - val_loss: 0.8960\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8489 - val_loss: 0.8968\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8285 - val_loss: 0.9022\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.9042\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6485 - val_loss: 0.9052\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7369 - val_loss: 0.9071\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7186 - val_loss: 0.9009\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8572 - val_loss: 0.9036\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7677 - val_loss: 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7311 - val_loss: 0.9042\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 0.9027\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7363 - val_loss: 0.9013\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8273 - val_loss: 0.8993\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6900 - val_loss: 0.8956\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 0.8940\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7222 - val_loss: 0.8961\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7044 - val_loss: 0.8987\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8017 - val_loss: 0.9013\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8255 - val_loss: 0.8961\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7043 - val_loss: 0.9011\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7367 - val_loss: 0.9012\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8293 - val_loss: 0.9007\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7689 - val_loss: 0.9032\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6886 - val_loss: 0.9079\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7219 - val_loss: 0.9053\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7858 - val_loss: 0.9083\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8208 - val_loss: 0.9059\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7447 - val_loss: 0.9014\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8001 - val_loss: 0.9013\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6673 - val_loss: 0.9061\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7884 - val_loss: 0.9086\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7761 - val_loss: 0.9057\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8113 - val_loss: 0.9047\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7405 - val_loss: 0.9016\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7961 - val_loss: 0.9028\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.8993\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9002 - val_loss: 0.8986\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8160 - val_loss: 0.8979\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7556 - val_loss: 0.8957\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6907 - val_loss: 0.8955\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7795 - val_loss: 0.8971\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7791 - val_loss: 0.8982\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7295 - val_loss: 0.8982\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7874 - val_loss: 0.8980\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7025 - val_loss: 0.8987\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7771 - val_loss: 0.8988\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8368 - val_loss: 0.8966\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7607 - val_loss: 0.8955\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7542 - val_loss: 0.8974\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.9003\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8520 - val_loss: 0.9021\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7278 - val_loss: 0.9059\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8015 - val_loss: 0.9060\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7182 - val_loss: 0.9007\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8165 - val_loss: 0.8990\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7890 - val_loss: 0.9000\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6883 - val_loss: 0.8985\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7583 - val_loss: 0.9010\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7410 - val_loss: 0.9009\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7686 - val_loss: 0.9018\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7843 - val_loss: 0.9025\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7923 - val_loss: 0.9029\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6929 - val_loss: 0.9028\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8195 - val_loss: 0.9023\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6409 - val_loss: 0.9075\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6958 - val_loss: 0.9045\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7680 - val_loss: 0.9059\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.9078\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7152 - val_loss: 0.9095\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7484 - val_loss: 0.9088\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7629 - val_loss: 0.9074\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8365 - val_loss: 0.9051\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7340 - val_loss: 0.9023\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7237 - val_loss: 0.9006\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7637 - val_loss: 0.9006\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7752 - val_loss: 0.8984\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7954 - val_loss: 0.8937\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7951 - val_loss: 0.8935\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8241 - val_loss: 0.8923\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8131 - val_loss: 0.8917\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7851 - val_loss: 0.8918\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7249 - val_loss: 0.8933\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7859 - val_loss: 0.8949\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7566 - val_loss: 0.8945\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7843 - val_loss: 0.8970\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6440 - val_loss: 0.8988\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8061 - val_loss: 0.8995\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6448 - val_loss: 0.8989\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7524 - val_loss: 0.9012\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7454 - val_loss: 0.9095\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7361 - val_loss: 0.9066\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6851 - val_loss: 0.9052\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8055 - val_loss: 0.9014\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7677 - val_loss: 0.8998\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7776 - val_loss: 0.9000\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7779 - val_loss: 0.8999\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7672 - val_loss: 0.8976\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7552 - val_loss: 0.8992\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7085 - val_loss: 0.9011\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7164 - val_loss: 0.8988\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7651 - val_loss: 0.8992\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7989 - val_loss: 0.8962\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - val_loss: 0.8996\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7556 - val_loss: 0.8993\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8178 - val_loss: 0.9028\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7318 - val_loss: 0.9036\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7078 - val_loss: 0.9043\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7040 - val_loss: 0.9052\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6960 - val_loss: 0.9054\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8542 - val_loss: 0.9037\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7562 - val_loss: 0.9023\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8448 - val_loss: 0.8997\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7607 - val_loss: 0.8998\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7678 - val_loss: 0.8979\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8226 - val_loss: 0.8971\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7537 - val_loss: 0.9011\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7936 - val_loss: 0.9004\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6599 - val_loss: 0.9062\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7601 - val_loss: 0.9093\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7851 - val_loss: 0.9106\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7297 - val_loss: 0.9116\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7578 - val_loss: 0.9076\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8451 - val_loss: 0.9065\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7617 - val_loss: 0.9007\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7548 - val_loss: 0.9009\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8274 - val_loss: 0.8990\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8462 - val_loss: 0.9020\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6939 - val_loss: 0.9020\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7862 - val_loss: 0.9026\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7683 - val_loss: 0.9066\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7568 - val_loss: 0.9070\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7509 - val_loss: 0.9059\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7950 - val_loss: 0.9067\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7482 - val_loss: 0.9068\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7271 - val_loss: 0.9065\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7419 - val_loss: 0.9056\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8509 - val_loss: 0.9042\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7718 - val_loss: 0.9035\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7378 - val_loss: 0.9079\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6734 - val_loss: 0.9109\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8021 - val_loss: 0.9078\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7425 - val_loss: 0.9051\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8286 - val_loss: 0.9018\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7062 - val_loss: 0.8979\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7367 - val_loss: 0.9023\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7591 - val_loss: 0.9014\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7373 - val_loss: 0.8990\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7192 - val_loss: 0.8964\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8363 - val_loss: 0.8982\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7525 - val_loss: 0.9009\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6962 - val_loss: 0.9005\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8032 - val_loss: 0.9015\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8453 - val_loss: 0.9036\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8386 - val_loss: 0.9039\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8196 - val_loss: 0.9021\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6761 - val_loss: 0.9076\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7034 - val_loss: 0.9073\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8659 - val_loss: 0.9068\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7371 - val_loss: 0.9026\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7838 - val_loss: 0.9066\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7648 - val_loss: 0.9077\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7796 - val_loss: 0.9116\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8294 - val_loss: 0.9061\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8195 - val_loss: 0.9050\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8105 - val_loss: 0.9024\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7062 - val_loss: 0.9135\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7538 - val_loss: 0.9140\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7344 - val_loss: 0.9140\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7734 - val_loss: 0.9197\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7346 - val_loss: 0.9186\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8144 - val_loss: 0.9201\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6262 - val_loss: 0.9239\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7725 - val_loss: 0.9194\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8157 - val_loss: 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7298 - val_loss: 0.9146\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6947 - val_loss: 0.9155\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7360 - val_loss: 0.9139\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7791 - val_loss: 0.9131\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6961 - val_loss: 0.9095\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7190 - val_loss: 0.9126\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7687 - val_loss: 0.9099\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9119\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8461 - val_loss: 0.9093\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6486 - val_loss: 0.9080\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7671 - val_loss: 0.9102\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7997 - val_loss: 0.9090\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6442 - val_loss: 0.9128\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7561 - val_loss: 0.9110\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6658 - val_loss: 0.9115\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7987 - val_loss: 0.9091\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6632 - val_loss: 0.9123\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7625 - val_loss: 0.9163\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7867 - val_loss: 0.9150\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6609 - val_loss: 0.9188\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8167 - val_loss: 0.9168\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7961 - val_loss: 0.9196\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7521 - val_loss: 0.9194\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6996 - val_loss: 0.9126\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7704 - val_loss: 0.9086\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7011 - val_loss: 0.9082\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7286 - val_loss: 0.9065\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7218 - val_loss: 0.9087\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6914 - val_loss: 0.9089\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6996 - val_loss: 0.9108\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8555 - val_loss: 0.9123\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8502 - val_loss: 0.9111\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7710 - val_loss: 0.9105\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7621 - val_loss: 0.9086\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7048 - val_loss: 0.9111\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8009 - val_loss: 0.9097\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8057 - val_loss: 0.9090\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7191 - val_loss: 0.9158\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6964 - val_loss: 0.9123\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7086 - val_loss: 0.9111\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7072 - val_loss: 0.9135\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7252 - val_loss: 0.9119\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7452 - val_loss: 0.9117\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7488 - val_loss: 0.9099\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8064 - val_loss: 0.9096\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8080 - val_loss: 0.9090\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6944 - val_loss: 0.9088\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7640 - val_loss: 0.9100\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6916 - val_loss: 0.9094\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7655 - val_loss: 0.9062\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7792 - val_loss: 0.9051\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7660 - val_loss: 0.9052\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7905 - val_loss: 0.9036\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6914 - val_loss: 0.9091\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8203 - val_loss: 0.9076\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7776 - val_loss: 0.9030\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6526 - val_loss: 0.9050\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8168 - val_loss: 0.9075\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7099 - val_loss: 0.9070\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6989 - val_loss: 0.9097\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6989 - val_loss: 0.9112\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6964 - val_loss: 0.9185\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8410 - val_loss: 0.9200\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8117 - val_loss: 0.9191\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9114\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7653 - val_loss: 0.9060\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7928 - val_loss: 0.9060\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8182 - val_loss: 0.9061\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7036 - val_loss: 0.9069\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7781 - val_loss: 0.9090\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6444 - val_loss: 0.9125\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7138 - val_loss: 0.9109\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8370 - val_loss: 0.9082\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6560 - val_loss: 0.9068\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7255 - val_loss: 0.9075\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8344 - val_loss: 0.9063\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7279 - val_loss: 0.9110\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8197 - val_loss: 0.9095\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8449 - val_loss: 0.9096\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8797 - val_loss: 0.9078\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6928 - val_loss: 0.9140\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7115 - val_loss: 0.9123\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7939 - val_loss: 0.9105\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8447 - val_loss: 0.9136\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6890 - val_loss: 0.9130\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6433 - val_loss: 0.9128\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer = 'sgd', loss = 'mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f13cb4aa5d0>, <tensorflow.python.keras.layers.core.Dense object at 0x7f13cb416890>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = np.arange(1, 500+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(model._layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.8049 - val_loss: 2.2743\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5866 - val_loss: 2.0297\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.6056 - val_loss: 1.8328\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.2908 - val_loss: 1.6577\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8248 - val_loss: 1.4822\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.5863 - val_loss: 1.3363\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4805 - val_loss: 1.2335\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4816 - val_loss: 1.1607\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2279 - val_loss: 1.1111\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0725 - val_loss: 1.0644\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9980 - val_loss: 1.0275\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1417 - val_loss: 0.9994\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9960 - val_loss: 0.9775\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9407 - val_loss: 0.9568\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9243 - val_loss: 0.9395\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9413 - val_loss: 0.9309\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9491 - val_loss: 0.9216\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8991 - val_loss: 0.9132\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7222 - val_loss: 0.9113\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8237 - val_loss: 0.9039\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6763 - val_loss: 0.8997\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7879 - val_loss: 0.8996\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7441 - val_loss: 0.8989\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8273 - val_loss: 0.8984\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8380 - val_loss: 0.8952\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7492 - val_loss: 0.8939\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7344 - val_loss: 0.8965\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7382 - val_loss: 0.8991\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7080 - val_loss: 0.8969\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8053 - val_loss: 0.8938\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7828 - val_loss: 0.8947\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7062 - val_loss: 0.8955\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6833 - val_loss: 0.8938\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7621 - val_loss: 0.8927\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7945 - val_loss: 0.8919\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7588 - val_loss: 0.8940\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7259 - val_loss: 0.8939\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7937 - val_loss: 0.8942\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7362 - val_loss: 0.8995\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9031\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7159 - val_loss: 0.9010\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6895 - val_loss: 0.8984\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8083 - val_loss: 0.9009\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6961 - val_loss: 0.9067\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8445 - val_loss: 0.9054\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8103 - val_loss: 0.9056\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7058 - val_loss: 0.9049\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7017 - val_loss: 0.9018\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7907 - val_loss: 0.9025\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8338 - val_loss: 0.9041\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8285 - val_loss: 0.8991\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 0.9017\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7851 - val_loss: 0.9003\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7663 - val_loss: 0.8999\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8418 - val_loss: 0.8987\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7334 - val_loss: 0.8981\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8718 - val_loss: 0.8982\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7824 - val_loss: 0.8997\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7713 - val_loss: 0.8992\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7209 - val_loss: 0.9011\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7808 - val_loss: 0.9005\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8002 - val_loss: 0.9000\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8153 - val_loss: 0.8995\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7907 - val_loss: 0.9029\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7484 - val_loss: 0.9031\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7785 - val_loss: 0.9043\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7100 - val_loss: 0.9054\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7288 - val_loss: 0.9046\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7333 - val_loss: 0.9048\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6828 - val_loss: 0.9028\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8963 - val_loss: 0.9012\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7642 - val_loss: 0.9001\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6384 - val_loss: 0.9020\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6714 - val_loss: 0.8998\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8105 - val_loss: 0.8972\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7517 - val_loss: 0.8954\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7080 - val_loss: 0.9000\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6896 - val_loss: 0.9059\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7636 - val_loss: 0.9091\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7151 - val_loss: 0.9059\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7419 - val_loss: 0.9087\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6761 - val_loss: 0.9068\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7697 - val_loss: 0.9087\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7740 - val_loss: 0.9113\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8314 - val_loss: 0.9044\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7111 - val_loss: 0.9007\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7293 - val_loss: 0.9004\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7654 - val_loss: 0.9015\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7537 - val_loss: 0.8989\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7140 - val_loss: 0.8993\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6933 - val_loss: 0.9048\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7761 - val_loss: 0.9040\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8093 - val_loss: 0.9045\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7489 - val_loss: 0.9030\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7040 - val_loss: 0.9013\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6622 - val_loss: 0.9042\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6734 - val_loss: 0.9032\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7947 - val_loss: 0.9014\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6668 - val_loss: 0.9008\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6374 - val_loss: 0.8999\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7667 - val_loss: 0.8978\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7074 - val_loss: 0.9008\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7249 - val_loss: 0.8971\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 0.8996\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8356 - val_loss: 0.9016\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7352 - val_loss: 0.9015\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7555 - val_loss: 0.9028\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8228 - val_loss: 0.9035\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8456 - val_loss: 0.9045\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7193 - val_loss: 0.9090\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8252 - val_loss: 0.9091\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8456 - val_loss: 0.9070\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7095 - val_loss: 0.9031\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7085 - val_loss: 0.9030\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8207 - val_loss: 0.9031\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7376 - val_loss: 0.9015\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8358 - val_loss: 0.9023\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7853 - val_loss: 0.9005\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7396 - val_loss: 0.9041\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6833 - val_loss: 0.9049\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8060 - val_loss: 0.9046\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7861 - val_loss: 0.9071\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8248 - val_loss: 0.9046\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7831 - val_loss: 0.9077\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7787 - val_loss: 0.9095\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7835 - val_loss: 0.9051\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7903 - val_loss: 0.9090\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8207 - val_loss: 0.9076\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7827 - val_loss: 0.9078\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8028 - val_loss: 0.9071\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7856 - val_loss: 0.9066\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8177 - val_loss: 0.9077\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7581 - val_loss: 0.9053\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7723 - val_loss: 0.9032\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7500 - val_loss: 0.9052\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7124 - val_loss: 0.9020\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7834 - val_loss: 0.9009\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7052 - val_loss: 0.8997\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8021 - val_loss: 0.8993\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6993 - val_loss: 0.8975\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7096 - val_loss: 0.8947\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6751 - val_loss: 0.9021\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7946 - val_loss: 0.9021\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7155 - val_loss: 0.8997\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7145 - val_loss: 0.9025\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6924 - val_loss: 0.9069\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7124 - val_loss: 0.9064\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8415 - val_loss: 0.9082\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8125 - val_loss: 0.9078\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7710 - val_loss: 0.9077\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8776 - val_loss: 0.9068\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7805 - val_loss: 0.9071\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - val_loss: 0.9055\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7679 - val_loss: 0.9044\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7000 - val_loss: 0.9063\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6647 - val_loss: 0.9040\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7089 - val_loss: 0.9063\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8619 - val_loss: 0.9084\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8467 - val_loss: 0.9072\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8509 - val_loss: 0.9103\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6699 - val_loss: 0.9083\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7409 - val_loss: 0.9108\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8847 - val_loss: 0.9132\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7586 - val_loss: 0.9157\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8167 - val_loss: 0.9136\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.9133\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7371 - val_loss: 0.9134\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7031 - val_loss: 0.9158\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7528 - val_loss: 0.9139\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8617 - val_loss: 0.9131\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7177 - val_loss: 0.9127\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7013 - val_loss: 0.9114\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8183 - val_loss: 0.9096\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7089 - val_loss: 0.9090\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6322 - val_loss: 0.9135\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7334 - val_loss: 0.9132\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7875 - val_loss: 0.9095\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7173 - val_loss: 0.9098\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8294 - val_loss: 0.9136\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8439 - val_loss: 0.9160\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6425 - val_loss: 0.9164\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7968 - val_loss: 0.9164\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6355 - val_loss: 0.9148\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7809 - val_loss: 0.9121\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7351 - val_loss: 0.9066\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7050 - val_loss: 0.9064\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7353 - val_loss: 0.9067\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8487 - val_loss: 0.9042\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7763 - val_loss: 0.9023\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7520 - val_loss: 0.8987\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8129 - val_loss: 0.9006\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6735 - val_loss: 0.8983\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8739 - val_loss: 0.9016\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7226 - val_loss: 0.9019\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7564 - val_loss: 0.9025\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.9019\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7244 - val_loss: 0.9007\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7346 - val_loss: 0.9021\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7626 - val_loss: 0.9019\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6938 - val_loss: 0.9006\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7944 - val_loss: 0.9000\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6914 - val_loss: 0.9043\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7499 - val_loss: 0.9041\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8323 - val_loss: 0.9038\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 0.9025\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7216 - val_loss: 0.9041\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7518 - val_loss: 0.9021\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7350 - val_loss: 0.9036\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7935 - val_loss: 0.8975\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6867 - val_loss: 0.9003\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6986 - val_loss: 0.9055\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7261 - val_loss: 0.9037\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7354 - val_loss: 0.9059\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8423 - val_loss: 0.9075\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7847 - val_loss: 0.9062\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7009 - val_loss: 0.9039\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8032 - val_loss: 0.9070\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8192 - val_loss: 0.9059\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7045 - val_loss: 0.8986\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7655 - val_loss: 0.8992\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7519 - val_loss: 0.9014\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6765 - val_loss: 0.9019\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9012\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7565 - val_loss: 0.9008\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7512 - val_loss: 0.9014\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7064 - val_loss: 0.9013\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8056 - val_loss: 0.9024\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7601 - val_loss: 0.9052\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7604 - val_loss: 0.9037\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7661 - val_loss: 0.9046\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7827 - val_loss: 0.9039\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6786 - val_loss: 0.9075\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6876 - val_loss: 0.9104\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6890 - val_loss: 0.9093\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7597 - val_loss: 0.9113\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7590 - val_loss: 0.9098\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7906 - val_loss: 0.9119\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8123 - val_loss: 0.9086\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6642 - val_loss: 0.9135\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7525 - val_loss: 0.9155\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6762 - val_loss: 0.9165\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7838 - val_loss: 0.9165\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7799 - val_loss: 0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7590 - val_loss: 0.9248\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7665 - val_loss: 0.9199\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8551 - val_loss: 0.9182\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7126 - val_loss: 0.9191\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6896 - val_loss: 0.9135\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8018 - val_loss: 0.9126\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7638 - val_loss: 0.9113\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7904 - val_loss: 0.9081\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8679 - val_loss: 0.9043\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7455 - val_loss: 0.8997\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7216 - val_loss: 0.8967\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7584 - val_loss: 0.8963\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7408 - val_loss: 0.8979\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7575 - val_loss: 0.8964\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7284 - val_loss: 0.8935\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7177 - val_loss: 0.8910\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7790 - val_loss: 0.8922\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8015 - val_loss: 0.8948\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7215 - val_loss: 0.8948\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6549 - val_loss: 0.8948\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6991 - val_loss: 0.8955\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6439 - val_loss: 0.8951\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8060 - val_loss: 0.8975\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7280 - val_loss: 0.8955\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7713 - val_loss: 0.8969\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8667 - val_loss: 0.8972\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8669 - val_loss: 0.8996\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7044 - val_loss: 0.9005\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7039 - val_loss: 0.8965\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7186 - val_loss: 0.8954\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7520 - val_loss: 0.8941\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7876 - val_loss: 0.8895\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7474 - val_loss: 0.8945\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8040 - val_loss: 0.8945\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7827 - val_loss: 0.8976\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7123 - val_loss: 0.8981\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8562 - val_loss: 0.8998\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6741 - val_loss: 0.8997\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7744 - val_loss: 0.8996\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7232 - val_loss: 0.9017\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8144 - val_loss: 0.9045\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8431 - val_loss: 0.9056\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7376 - val_loss: 0.9043\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8013 - val_loss: 0.9055\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6806 - val_loss: 0.9111\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8200 - val_loss: 0.9100\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7097 - val_loss: 0.9132\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7262 - val_loss: 0.9140\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7832 - val_loss: 0.9113\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8464 - val_loss: 0.9091\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7512 - val_loss: 0.9079\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6969 - val_loss: 0.9085\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7950 - val_loss: 0.9112\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8103 - val_loss: 0.9115\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8054 - val_loss: 0.9096\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7741 - val_loss: 0.9111\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8162 - val_loss: 0.9080\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7244 - val_loss: 0.9067\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7902 - val_loss: 0.9090\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8006 - val_loss: 0.9071\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6567 - val_loss: 0.9061\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7350 - val_loss: 0.9034\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7168 - val_loss: 0.9065\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7546 - val_loss: 0.9068\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7152 - val_loss: 0.9061\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7141 - val_loss: 0.9085\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7324 - val_loss: 0.9113\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6831 - val_loss: 0.9112\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7564 - val_loss: 0.9098\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7521 - val_loss: 0.9086\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7639 - val_loss: 0.9077\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7465 - val_loss: 0.9104\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8097 - val_loss: 0.9061\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7487 - val_loss: 0.9059\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8070 - val_loss: 0.9075\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8275 - val_loss: 0.9095\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7845 - val_loss: 0.9105\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7005 - val_loss: 0.9088\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7254 - val_loss: 0.9099\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7211 - val_loss: 0.9100\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8169 - val_loss: 0.9073\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7469 - val_loss: 0.9078\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7258 - val_loss: 0.9061\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8210 - val_loss: 0.9040\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6856 - val_loss: 0.9079\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7677 - val_loss: 0.9088\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9136\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7845 - val_loss: 0.9122\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8037 - val_loss: 0.9145\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6926 - val_loss: 0.9127\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7249 - val_loss: 0.9120\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7326 - val_loss: 0.9108\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7109 - val_loss: 0.9074\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7498 - val_loss: 0.9057\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7155 - val_loss: 0.9052\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8168 - val_loss: 0.9078\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7514 - val_loss: 0.9064\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7502 - val_loss: 0.9088\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7542 - val_loss: 0.9129\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7385 - val_loss: 0.9118\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8156 - val_loss: 0.9095\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7295 - val_loss: 0.9106\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7605 - val_loss: 0.9111\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7656 - val_loss: 0.9086\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7102 - val_loss: 0.9159\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8687 - val_loss: 0.9124\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7026 - val_loss: 0.9127\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7873 - val_loss: 0.9094\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7619 - val_loss: 0.9073\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7458 - val_loss: 0.9030\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6790 - val_loss: 0.9063\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7970 - val_loss: 0.9078\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8115 - val_loss: 0.9069\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6855 - val_loss: 0.9085\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7962 - val_loss: 0.9065\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7834 - val_loss: 0.9083\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6616 - val_loss: 0.9081\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6641 - val_loss: 0.9057\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - val_loss: 0.9038\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7349 - val_loss: 0.9010\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7367 - val_loss: 0.8997\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7875 - val_loss: 0.9013\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7107 - val_loss: 0.9041\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6955 - val_loss: 0.9048\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7605 - val_loss: 0.9008\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7335 - val_loss: 0.9039\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6326 - val_loss: 0.9075\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7479 - val_loss: 0.9080\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7309 - val_loss: 0.9051\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7603 - val_loss: 0.9068\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7217 - val_loss: 0.9076\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7751 - val_loss: 0.9059\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7122 - val_loss: 0.9029\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7950 - val_loss: 0.9014\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7848 - val_loss: 0.9015\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6978 - val_loss: 0.9044\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6937 - val_loss: 0.9025\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6989 - val_loss: 0.9026\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6863 - val_loss: 0.9068\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7430 - val_loss: 0.9054\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6913 - val_loss: 0.9049\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8037 - val_loss: 0.9087\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7715 - val_loss: 0.9051\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8172 - val_loss: 0.9052\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7455 - val_loss: 0.9054\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7545 - val_loss: 0.9043\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6608 - val_loss: 0.9070\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7305 - val_loss: 0.9128\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7523 - val_loss: 0.9111\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7168 - val_loss: 0.9099\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8122 - val_loss: 0.9078\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8114 - val_loss: 0.9078\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7648 - val_loss: 0.9096\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7268 - val_loss: 0.9124\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6941 - val_loss: 0.9079\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8360 - val_loss: 0.9025\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7594 - val_loss: 0.9016\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7495 - val_loss: 0.9006\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8293 - val_loss: 0.9006\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8589 - val_loss: 0.8988\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8319 - val_loss: 0.8971\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7970 - val_loss: 0.8978\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6744 - val_loss: 0.8980\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8457 - val_loss: 0.8993\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7512 - val_loss: 0.8963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7741 - val_loss: 0.8954\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8446 - val_loss: 0.8923\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7327 - val_loss: 0.8936\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7472 - val_loss: 0.8926\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6974 - val_loss: 0.8914\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8148 - val_loss: 0.8918\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7791 - val_loss: 0.8928\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7242 - val_loss: 0.8961\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7283 - val_loss: 0.9002\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7450 - val_loss: 0.9025\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7952 - val_loss: 0.9030\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7649 - val_loss: 0.8985\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8937 - val_loss: 0.8996\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7942 - val_loss: 0.9000\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8280 - val_loss: 0.9008\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7335 - val_loss: 0.8998\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7405 - val_loss: 0.9012\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7806 - val_loss: 0.9030\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6866 - val_loss: 0.9072\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8467 - val_loss: 0.9078\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7772 - val_loss: 0.9073\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7322 - val_loss: 0.9109\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7333 - val_loss: 0.9084\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8210 - val_loss: 0.9081\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7375 - val_loss: 0.9087\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7962 - val_loss: 0.9066\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7032 - val_loss: 0.9074\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7259 - val_loss: 0.9094\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7029 - val_loss: 0.9080\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7596 - val_loss: 0.9046\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7306 - val_loss: 0.9024\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7231 - val_loss: 0.9024\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7699 - val_loss: 0.9014\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7383 - val_loss: 0.9007\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7148 - val_loss: 0.9021\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8043 - val_loss: 0.9044\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7903 - val_loss: 0.9016\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7841 - val_loss: 0.9049\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8341 - val_loss: 0.9027\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7277 - val_loss: 0.9036\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7666 - val_loss: 0.9018\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7902 - val_loss: 0.9056\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7929 - val_loss: 0.9048\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7861 - val_loss: 0.9044\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7386 - val_loss: 0.9048\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7349 - val_loss: 0.9076\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7328 - val_loss: 0.9022\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7377 - val_loss: 0.9022\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7713 - val_loss: 0.9029\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6697 - val_loss: 0.9022\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6817 - val_loss: 0.9053\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7348 - val_loss: 0.9060\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7423 - val_loss: 0.9062\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7449 - val_loss: 0.9107\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7614 - val_loss: 0.9134\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7824 - val_loss: 0.9140\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7876 - val_loss: 0.9108\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6879 - val_loss: 0.9183\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7492 - val_loss: 0.9212\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7704 - val_loss: 0.9189\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7257 - val_loss: 0.9143\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8181 - val_loss: 0.9103\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7604 - val_loss: 0.9089\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7777 - val_loss: 0.9094\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7071 - val_loss: 0.9107\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7616 - val_loss: 0.9090\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8198 - val_loss: 0.9076\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 0.9042\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.9081\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7214 - val_loss: 0.9130\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6432 - val_loss: 0.9115\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8019 - val_loss: 0.9119\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7905 - val_loss: 0.9159\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8064 - val_loss: 0.9140\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7524 - val_loss: 0.9161\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7413 - val_loss: 0.9143\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7278 - val_loss: 0.9116\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7753 - val_loss: 0.9098\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7034 - val_loss: 0.9063\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7557 - val_loss: 0.9077\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7515 - val_loss: 0.9034\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7945 - val_loss: 0.9022\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7621 - val_loss: 0.9025\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8178 - val_loss: 0.9023\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8163 - val_loss: 0.9031\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8068 - val_loss: 0.9038\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7282 - val_loss: 0.9038\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7059 - val_loss: 0.9008\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7123 - val_loss: 0.9016\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8639 - val_loss: 0.9000\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7906 - val_loss: 0.8969\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7187 - val_loss: 0.8952\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "input = tf.keras.Input(shape=(1,))\n",
    "output = tf.keras.layers.Dense(1)(input)\n",
    "model = tf.keras.Model(input, output)\n",
    "model.summary()\n",
    "model.compile(optimizer='sgd',loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9504249691963196"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "model.load_weights('simple_weights.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9504249691963196"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('simple_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 13.2715 - val_loss: 7.1906\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 10.5768 - val_loss: 5.8994\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.0726 - val_loss: 4.8320\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.5562 - val_loss: 4.0008\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.8378 - val_loss: 3.3237\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.4746 - val_loss: 2.7839\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.1857 - val_loss: 2.3588\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.6322 - val_loss: 2.0140\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2145 - val_loss: 1.7428\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.0715 - val_loss: 1.5273\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3243 - val_loss: 1.3587\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.9899 - val_loss: 1.2214\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9884 - val_loss: 1.1131\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7684 - val_loss: 1.0314\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2881 - val_loss: 0.9670\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2170 - val_loss: 0.9182\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2975 - val_loss: 0.8792\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0770 - val_loss: 0.8513\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1154 - val_loss: 0.8309\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0368 - val_loss: 0.8154\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9418 - val_loss: 0.8032\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9171 - val_loss: 0.7960\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9775 - val_loss: 0.7903\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9593 - val_loss: 0.7872\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9064 - val_loss: 0.7860\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8025 - val_loss: 0.7858\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8644 - val_loss: 0.7867\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8265 - val_loss: 0.7879\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8790 - val_loss: 0.7898\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9146 - val_loss: 0.7919\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7308 - val_loss: 0.7944\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "callback_list = [tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5', monitor='val_loss', save_best_only=True), \n",
    "                tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    "\n",
    "histroy = model.fit(x_train, y_train, epochs=500, validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label = 'Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label = 'Validation liss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_arr = np.arange(-2, 2, 0.1)\n",
    "y_arr = model.predict(x_arr)\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'bo')\n",
    "plt.plot(x_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_arr, '-r', lw=3)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 9.0509 - val_loss: 5.3852\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.2924 - val_loss: 4.4629\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.5621 - val_loss: 3.7687\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.9171 - val_loss: 3.2278\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.9674 - val_loss: 2.7534\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.7402 - val_loss: 2.4456\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.0394 - val_loss: 2.1762\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.5066 - val_loss: 1.9297\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.4163 - val_loss: 1.7432\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.9028 - val_loss: 1.5963\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7359 - val_loss: 1.4811\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5155 - val_loss: 1.3770\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4934 - val_loss: 1.2889\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2245 - val_loss: 1.2301\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1366 - val_loss: 1.1730\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1387 - val_loss: 1.1285\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0277 - val_loss: 1.0955\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0271 - val_loss: 1.0680\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9997 - val_loss: 1.0447\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9188 - val_loss: 1.0258\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8741 - val_loss: 1.0078\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9443 - val_loss: 0.9932\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8596 - val_loss: 0.9767\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8332 - val_loss: 0.9712\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8999 - val_loss: 0.9635\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7888 - val_loss: 0.9549\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7767 - val_loss: 0.9539\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7828 - val_loss: 0.9499\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6899 - val_loss: 0.9463\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7808 - val_loss: 0.9474\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7850 - val_loss: 0.9456\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7054 - val_loss: 0.9433\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6890 - val_loss: 0.9470\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8236 - val_loss: 0.9447\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7699 - val_loss: 0.9480\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8324 - val_loss: 0.9468\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7745 - val_loss: 0.9440\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7901 - val_loss: 0.9399\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7751 - val_loss: 0.9422\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8169 - val_loss: 0.9430\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7522 - val_loss: 0.9425\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8424 - val_loss: 0.9419\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8195 - val_loss: 0.9417\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7302 - val_loss: 0.9396\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8060 - val_loss: 0.9404\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6812 - val_loss: 0.9373\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7949 - val_loss: 0.9357\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8061 - val_loss: 0.9382\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8272 - val_loss: 0.9374\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8260 - val_loss: 0.9357\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8124 - val_loss: 0.9348\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7744 - val_loss: 0.9347\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7291 - val_loss: 0.9372\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7443 - val_loss: 0.9340\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7101 - val_loss: 0.9326\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8059 - val_loss: 0.9337\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8207 - val_loss: 0.9361\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7083 - val_loss: 0.9348\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8474 - val_loss: 0.9342\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7882 - val_loss: 0.9327\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7128 - val_loss: 0.9347\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6584 - val_loss: 0.9346\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7478 - val_loss: 0.9343\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7461 - val_loss: 0.9369\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6978 - val_loss: 0.9364\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8205 - val_loss: 0.9402\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7793 - val_loss: 0.9372\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7181 - val_loss: 0.9394\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6952 - val_loss: 0.9422\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7870 - val_loss: 0.9381\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7406 - val_loss: 0.9332\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7543 - val_loss: 0.9278\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7850 - val_loss: 0.9259\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7112 - val_loss: 0.9287\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8610 - val_loss: 0.9296\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7706 - val_loss: 0.9295\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8043 - val_loss: 0.9322\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7516 - val_loss: 0.9317\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7591 - val_loss: 0.9369\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7313 - val_loss: 0.9348\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7504 - val_loss: 0.9373\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8966 - val_loss: 0.9351\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7363 - val_loss: 0.9371\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8381 - val_loss: 0.9369\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8087 - val_loss: 0.9376\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7637 - val_loss: 0.9341\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8000 - val_loss: 0.9342\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8795 - val_loss: 0.9316\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7399 - val_loss: 0.9273\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8082 - val_loss: 0.9270\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8185 - val_loss: 0.9285\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7953 - val_loss: 0.9276\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8024 - val_loss: 0.9280\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7593 - val_loss: 0.9264\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6980 - val_loss: 0.9220\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8275 - val_loss: 0.9252\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7719 - val_loss: 0.9290\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7657 - val_loss: 0.9271\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7193 - val_loss: 0.9281\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7233 - val_loss: 0.9251\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7254 - val_loss: 0.9252\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7831 - val_loss: 0.9259\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7800 - val_loss: 0.9303\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7024 - val_loss: 0.9296\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8363 - val_loss: 0.9310\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7725 - val_loss: 0.9325\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8046 - val_loss: 0.9345\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7978 - val_loss: 0.9318\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7968 - val_loss: 0.9314\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7587 - val_loss: 0.9296\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8693 - val_loss: 0.9318\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8399 - val_loss: 0.9305\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7245 - val_loss: 0.9371\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7018 - val_loss: 0.9373\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7446 - val_loss: 0.9406\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8208 - val_loss: 0.9364\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7392 - val_loss: 0.9353\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8251 - val_loss: 0.9357\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7918 - val_loss: 0.9369\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7314 - val_loss: 0.9398\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8418 - val_loss: 0.9380\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7915 - val_loss: 0.9344\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8282 - val_loss: 0.9376\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7092 - val_loss: 0.9446\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7908 - val_loss: 0.9416\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7088 - val_loss: 0.9422\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7151 - val_loss: 0.9409\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8132 - val_loss: 0.9408\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6955 - val_loss: 0.9502\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8378 - val_loss: 0.9488\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7808 - val_loss: 0.9495\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8160 - val_loss: 0.9473\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7856 - val_loss: 0.9460\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7641 - val_loss: 0.9436\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8055 - val_loss: 0.9414\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8102 - val_loss: 0.9387\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8811 - val_loss: 0.9355\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7332 - val_loss: 0.9382\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7798 - val_loss: 0.9356\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8085 - val_loss: 0.9344\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8140 - val_loss: 0.9336\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8598 - val_loss: 0.9324\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8515 - val_loss: 0.9352\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7627 - val_loss: 0.9333\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7286 - val_loss: 0.9310\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7271 - val_loss: 0.9287\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7281 - val_loss: 0.9260\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7405 - val_loss: 0.9355\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8477 - val_loss: 0.9317\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7279 - val_loss: 0.9324\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8323 - val_loss: 0.9330\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7915 - val_loss: 0.9280\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7851 - val_loss: 0.9287\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7444 - val_loss: 0.9270\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6840 - val_loss: 0.9295\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8573 - val_loss: 0.9338\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8441 - val_loss: 0.9310\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8943 - val_loss: 0.9326\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7884 - val_loss: 0.9307\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8205 - val_loss: 0.9303\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7860 - val_loss: 0.9274\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8094 - val_loss: 0.9275\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7417 - val_loss: 0.9288\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7515 - val_loss: 0.9323\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8677 - val_loss: 0.9321\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7566 - val_loss: 0.9298\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8954 - val_loss: 0.9304\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7978 - val_loss: 0.9310\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7854 - val_loss: 0.9310\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7729 - val_loss: 0.9280\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7471 - val_loss: 0.9256\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8029 - val_loss: 0.9297\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7993 - val_loss: 0.9320\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7385 - val_loss: 0.9326\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8133 - val_loss: 0.9359\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7014 - val_loss: 0.9380\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8268 - val_loss: 0.9392\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7143 - val_loss: 0.9394\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8495 - val_loss: 0.9428\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7049 - val_loss: 0.9498\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7157 - val_loss: 0.9477\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8659 - val_loss: 0.9478\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7798 - val_loss: 0.9470\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8776 - val_loss: 0.9464\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7534 - val_loss: 0.9474\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8189 - val_loss: 0.9481\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7216 - val_loss: 0.9534\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7496 - val_loss: 0.9514\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7860 - val_loss: 0.9481\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8050 - val_loss: 0.9471\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7711 - val_loss: 0.9452\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7324 - val_loss: 0.9478\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7663 - val_loss: 0.9478\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7590 - val_loss: 0.9516\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7286 - val_loss: 0.9468\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7181 - val_loss: 0.9459\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7856 - val_loss: 0.9428\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8171 - val_loss: 0.9433\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7179 - val_loss: 0.9431\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8343 - val_loss: 0.9445\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7111 - val_loss: 0.9419\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7195 - val_loss: 0.9475\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7409 - val_loss: 0.9492\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8269 - val_loss: 0.9490\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7561 - val_loss: 0.9481\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8458 - val_loss: 0.9427\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6983 - val_loss: 0.9418\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6659 - val_loss: 0.9408\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8342 - val_loss: 0.9355\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7565 - val_loss: 0.9315\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8266 - val_loss: 0.9298\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7138 - val_loss: 0.9321\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7220 - val_loss: 0.9335\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7713 - val_loss: 0.9364\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7297 - val_loss: 0.9373\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7352 - val_loss: 0.9453\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8115 - val_loss: 0.9433\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7556 - val_loss: 0.9412\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8591 - val_loss: 0.9411\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8132 - val_loss: 0.9420\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7175 - val_loss: 0.9437\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8127 - val_loss: 0.9442\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6709 - val_loss: 0.9387\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8187 - val_loss: 0.9370\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7266 - val_loss: 0.9377\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8445 - val_loss: 0.9361\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7861 - val_loss: 0.9393\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7310 - val_loss: 0.9377\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8521 - val_loss: 0.9353\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8731 - val_loss: 0.9338\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7801 - val_loss: 0.9309\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8331 - val_loss: 0.9301\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7050 - val_loss: 0.9318\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7132 - val_loss: 0.9282\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8051 - val_loss: 0.9280\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8838 - val_loss: 0.9272\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8769 - val_loss: 0.9264\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7545 - val_loss: 0.9242\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7991 - val_loss: 0.9254\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8143 - val_loss: 0.9243\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7629 - val_loss: 0.9228\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8539 - val_loss: 0.9243\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7230 - val_loss: 0.9239\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7247 - val_loss: 0.9216\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7651 - val_loss: 0.9209\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7592 - val_loss: 0.9202\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7841 - val_loss: 0.9232\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7083 - val_loss: 0.9253\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7673 - val_loss: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8176 - val_loss: 0.9268\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7097 - val_loss: 0.9323\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7838 - val_loss: 0.9294\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8206 - val_loss: 0.9241\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8037 - val_loss: 0.9259\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8800 - val_loss: 0.9255\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7150 - val_loss: 0.9265\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8713 - val_loss: 0.9262\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8060 - val_loss: 0.9296\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8038 - val_loss: 0.9293\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8071 - val_loss: 0.9293\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7337 - val_loss: 0.9282\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8641 - val_loss: 0.9262\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8610 - val_loss: 0.9217\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7209 - val_loss: 0.9232\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7267 - val_loss: 0.9233\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7617 - val_loss: 0.9236\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7801 - val_loss: 0.9227\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7792 - val_loss: 0.9237\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7639 - val_loss: 0.9249\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8257 - val_loss: 0.9258\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7861 - val_loss: 0.9262\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7768 - val_loss: 0.9280\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8205 - val_loss: 0.9278\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 0.9246\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6808 - val_loss: 0.9348\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7774 - val_loss: 0.9316\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8006 - val_loss: 0.9305\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8752 - val_loss: 0.9295\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7122 - val_loss: 0.9374\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8772 - val_loss: 0.9323\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8832 - val_loss: 0.9325\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7142 - val_loss: 0.9344\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7620 - val_loss: 0.9348\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8278 - val_loss: 0.9353\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8302 - val_loss: 0.9346\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7143 - val_loss: 0.9335\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8251 - val_loss: 0.9364\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7994 - val_loss: 0.9377\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6867 - val_loss: 0.9360\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7728 - val_loss: 0.9329\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7318 - val_loss: 0.9353\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8105 - val_loss: 0.9325\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7744 - val_loss: 0.9312\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7989 - val_loss: 0.9305\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6777 - val_loss: 0.9294\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6918 - val_loss: 0.9262\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8447 - val_loss: 0.9235\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7356 - val_loss: 0.9220\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9052 - val_loss: 0.9250\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7550 - val_loss: 0.9269\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8269 - val_loss: 0.9267\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7529 - val_loss: 0.9292\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7857 - val_loss: 0.9278\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7688 - val_loss: 0.9315\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7926 - val_loss: 0.9336\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7967 - val_loss: 0.9338\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8702 - val_loss: 0.9342\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6877 - val_loss: 0.9312\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8225 - val_loss: 0.9341\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7658 - val_loss: 0.9304\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6830 - val_loss: 0.9306\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8161 - val_loss: 0.9279\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7184 - val_loss: 0.9316\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7320 - val_loss: 0.9325\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8077 - val_loss: 0.9321\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7772 - val_loss: 0.9338\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7020 - val_loss: 0.9324\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8032 - val_loss: 0.9297\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7844 - val_loss: 0.9296\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7220 - val_loss: 0.9311\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8923 - val_loss: 0.9317\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8007 - val_loss: 0.9290\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8121 - val_loss: 0.9329\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8318 - val_loss: 0.9355\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7504 - val_loss: 0.9329\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7095 - val_loss: 0.9345\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7042 - val_loss: 0.9386\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8353 - val_loss: 0.9373\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8302 - val_loss: 0.9351\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8698 - val_loss: 0.9332\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8280 - val_loss: 0.9327\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7262 - val_loss: 0.9320\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7203 - val_loss: 0.9342\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7234 - val_loss: 0.9331\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7341 - val_loss: 0.9347\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7321 - val_loss: 0.9377\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7551 - val_loss: 0.9355\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8627 - val_loss: 0.9370\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8465 - val_loss: 0.9362\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7089 - val_loss: 0.9345\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7506 - val_loss: 0.9408\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7343 - val_loss: 0.9413\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8161 - val_loss: 0.9382\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7366 - val_loss: 0.9391\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8277 - val_loss: 0.9337\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7782 - val_loss: 0.9324\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7509 - val_loss: 0.9308\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6999 - val_loss: 0.9313\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8216 - val_loss: 0.9301\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8607 - val_loss: 0.9283\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7349 - val_loss: 0.9273\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7892 - val_loss: 0.9273\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7580 - val_loss: 0.9262\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8398 - val_loss: 0.9253\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7282 - val_loss: 0.9238\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8102 - val_loss: 0.9243\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8117 - val_loss: 0.9250\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8128 - val_loss: 0.9271\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8394 - val_loss: 0.9255\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8486 - val_loss: 0.9277\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7231 - val_loss: 0.9279\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7088 - val_loss: 0.9292\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6975 - val_loss: 0.9266\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7204 - val_loss: 0.9262\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7429 - val_loss: 0.9293\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9026 - val_loss: 0.9308\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8433 - val_loss: 0.9294\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7086 - val_loss: 0.9340\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7917 - val_loss: 0.9322\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.9334\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8818 - val_loss: 0.9337\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7876 - val_loss: 0.9331\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7572 - val_loss: 0.9339\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7403 - val_loss: 0.9340\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7242 - val_loss: 0.9391\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8018 - val_loss: 0.9398\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7373 - val_loss: 0.9354\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8076 - val_loss: 0.9284\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7652 - val_loss: 0.9314\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8035 - val_loss: 0.9304\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7694 - val_loss: 0.9332\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8393 - val_loss: 0.9321\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8229 - val_loss: 0.9292\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8114 - val_loss: 0.9350\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7919 - val_loss: 0.9339\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8260 - val_loss: 0.9308\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7879 - val_loss: 0.9299\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7570 - val_loss: 0.9285\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8665 - val_loss: 0.9296\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7980 - val_loss: 0.9289\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7936 - val_loss: 0.9299\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8039 - val_loss: 0.9303\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7919 - val_loss: 0.9310\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6485 - val_loss: 0.9334\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8881 - val_loss: 0.9321\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7549 - val_loss: 0.9323\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7443 - val_loss: 0.9369\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7219 - val_loss: 0.9356\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9096 - val_loss: 0.9369\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7897 - val_loss: 0.9373\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7736 - val_loss: 0.9384\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8596 - val_loss: 0.9364\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7420 - val_loss: 0.9325\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7295 - val_loss: 0.9396\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8517 - val_loss: 0.9364\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8169 - val_loss: 0.9326\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7041 - val_loss: 0.9342\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7152 - val_loss: 0.9301\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7466 - val_loss: 0.9307\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8445 - val_loss: 0.9309\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7911 - val_loss: 0.9304\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7660 - val_loss: 0.9302\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7226 - val_loss: 0.9360\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7838 - val_loss: 0.9366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7131 - val_loss: 0.9358\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7550 - val_loss: 0.9362\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8457 - val_loss: 0.9382\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8089 - val_loss: 0.9431\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7963 - val_loss: 0.9408\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7197 - val_loss: 0.9452\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7340 - val_loss: 0.9437\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7399 - val_loss: 0.9417\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6980 - val_loss: 0.9394\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7454 - val_loss: 0.9358\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7340 - val_loss: 0.9367\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8275 - val_loss: 0.9378\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8307 - val_loss: 0.9366\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7171 - val_loss: 0.9366\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7380 - val_loss: 0.9327\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7128 - val_loss: 0.9298\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7296 - val_loss: 0.9307\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7797 - val_loss: 0.9295\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8534 - val_loss: 0.9279\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7892 - val_loss: 0.9302\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8262 - val_loss: 0.9306\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7627 - val_loss: 0.9268\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7225 - val_loss: 0.9256\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8113 - val_loss: 0.9229\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8408 - val_loss: 0.9223\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7018 - val_loss: 0.9223\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7897 - val_loss: 0.9253\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8026 - val_loss: 0.9274\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7780 - val_loss: 0.9271\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7573 - val_loss: 0.9264\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7372 - val_loss: 0.9240\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7498 - val_loss: 0.9275\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8159 - val_loss: 0.9256\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7474 - val_loss: 0.9227\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - val_loss: 0.9249\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7033 - val_loss: 0.9256\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6730 - val_loss: 0.9318\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8669 - val_loss: 0.9300\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7601 - val_loss: 0.9278\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9136 - val_loss: 0.9281\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7146 - val_loss: 0.9339\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7301 - val_loss: 0.9321\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7736 - val_loss: 0.9301\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7538 - val_loss: 0.9326\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8526 - val_loss: 0.9317\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7267 - val_loss: 0.9330\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7721 - val_loss: 0.9341\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6942 - val_loss: 0.9376\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7309 - val_loss: 0.9371\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8128 - val_loss: 0.9340\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7640 - val_loss: 0.9336\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8476 - val_loss: 0.9325\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8693 - val_loss: 0.9325\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6747 - val_loss: 0.9377\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6697 - val_loss: 0.9421\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8731 - val_loss: 0.9424\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7686 - val_loss: 0.9407\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8409 - val_loss: 0.9439\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7717 - val_loss: 0.9404\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7547 - val_loss: 0.9371\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7907 - val_loss: 0.9396\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7083 - val_loss: 0.9345\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7944 - val_loss: 0.9307\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7507 - val_loss: 0.9315\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7539 - val_loss: 0.9366\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8300 - val_loss: 0.9379\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7910 - val_loss: 0.9379\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8109 - val_loss: 0.9369\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8571 - val_loss: 0.9380\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7406 - val_loss: 0.9404\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6970 - val_loss: 0.9359\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8949 - val_loss: 0.9381\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7591 - val_loss: 0.9402\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8230 - val_loss: 0.9379\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8240 - val_loss: 0.9372\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8226 - val_loss: 0.9354\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7766 - val_loss: 0.9335\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7706 - val_loss: 0.9360\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7668 - val_loss: 0.9347\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8359 - val_loss: 0.9349\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7811 - val_loss: 0.9338\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7836 - val_loss: 0.9299\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7801 - val_loss: 0.9289\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7528 - val_loss: 0.9293\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8293 - val_loss: 0.9255\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8287 - val_loss: 0.9291\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_dim=1, kernel_regularizer='l2'))\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "callback_list = [TensorBoard()]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input \n",
    "import tensorflow as tf\n",
    "input = tf.keras.Input(shape=(784,))\n",
    "hidden = tf.keras.layers.Dense(100)(input)\n",
    "output = tf.keras.layers.Dense(10)(hidden)\n",
    "\n",
    "model = tf.keras.Model(input, output)\n",
    "tf.keras.utils.plot_model(model, to_file='model_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
