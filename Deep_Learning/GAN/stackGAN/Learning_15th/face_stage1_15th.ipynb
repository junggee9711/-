{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greatest-problem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings:  (14261, 40)\n",
      "Embeddings shape: (14261, 40)\n",
      "embeddings:  (3565, 40)\n",
      "Embeddings shape: (3565, 40)\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n",
    "    concatenate, Flatten, Lambda, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "    \n",
    "   \n",
    "def load_class_ids(class_info_file_path):\n",
    "    \"\"\"\n",
    "    Load class ids from class_info.pickle file\n",
    "    \"\"\"\n",
    "    with open(class_info_file_path, 'rb') as f:\n",
    "        class_ids = pickle.load(f, encoding='latin1')\n",
    "        return class_ids\n",
    "\n",
    "\n",
    "def load_embeddings(embeddings_file_path):\n",
    "    \"\"\"\n",
    "    훈련된 텍스트 임베딩을 불러옴\n",
    "    \"\"\"\n",
    "    with open(embeddings_file_path, 'rb') as f:\n",
    "        embeddings = pickle.load(f, encoding='latin1')\n",
    "        embeddings = np.array(embeddings)\n",
    "        print('embeddings: ', embeddings.shape)\n",
    "    return embeddings\n",
    "\n",
    "def load_filenames(filenames_file_path):\n",
    "    \"\"\"\n",
    "    Load filenames.pickle file and return a list of all file names\n",
    "    \"\"\"\n",
    "    with open(filenames_file_path, 'rb') as f:\n",
    "        filenames = pickle.load(f, encoding='latin1')\n",
    "    return filenames\n",
    "\n",
    "def load_bounding_boxes(dataset_dir):\n",
    "    \"\"\"\n",
    "    이미지와 그에 상응하는 바운딩 박스를 짝지어 딕셔너리로 만들어 출력\n",
    "    \"\"\"\n",
    "    # 바운딩 박스 전체 경로\n",
    "    bounding_boxes_path = os.path.join(dataset_dir, 'list_bbox_celeba_pure_del.csv')\n",
    "    file_paths_path = os.path.join(dataset_dir, 'list_filenames.csv')\n",
    "\n",
    "    # bounding_boxes.txt 와 images.txt 파일을 읽어옴\n",
    "    df_bounding_boxes = pd.read_csv(bounding_boxes_path, header=None).astype(int)\n",
    "    df_file_names = pd.read_csv(file_paths_path, header=None)\n",
    "\n",
    "    # 전체 이미지 파일 명이 순서대로 적힌 리스트를 만듬\n",
    "    file_names = df_file_names[0].tolist() \n",
    "\n",
    "    # 파일 이름에 대응하는 바운딩 박스가 들어갈 딕셔너리를 만듬 (딕셔너리는 크기를 임의로 증가시킬수 있으므로 초기 사이즈는 아무렇게나)\n",
    "    filename_boundingbox_dict = {}\n",
    "\n",
    "    # 이미지 파일과 그에 해당하는 바운딩 박스를 딕셔너리로 만듬 (key = 이미지 파일 이름)\n",
    "    for i in range(0, len(file_names)):\n",
    "        # Get the bounding box\n",
    "        bounding_box = df_bounding_boxes.iloc[i][:].tolist()\n",
    "        key = file_names[i][:-4] + '.jpg'\n",
    "        filename_boundingbox_dict[key] = bounding_box\n",
    "\n",
    "    return filename_boundingbox_dict\n",
    "'''\n",
    "새 이미지가 크롭핑 되어있지 않기 크롭하기 위한 바운딩 박스 좌표 값이 파일에 주어지며,\n",
    "그 파일을 토대로 이미지를 크로핑 한 후,\n",
    "크로핑된 모든 이미지를 지정한 이미지 크기 (image_size) 값으로 바꾼다\n",
    "'''\n",
    "def get_img(img_path, bbox, image_size):\n",
    "    \"\"\"\n",
    "    Load and resize image\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    if bbox is not None:\n",
    "        pass\n",
    "    '''\n",
    "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
    "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
    "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
    "        y1 = np.maximum(0, center_y - R)\n",
    "        y2 = np.minimum(height, center_y + R)\n",
    "        x1 = np.maximum(0, center_x - R)\n",
    "        x2 = np.minimum(width, center_x + R)\n",
    "        img = img.crop([x1, y1, x2, y2])\n",
    "    '''\n",
    "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_dataset(filenames_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    filenames = load_filenames(filenames_file_path)\n",
    "    '''\n",
    "    class_ids = load_class_ids(class_info_file_path)\n",
    "    '''\n",
    "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n",
    "    all_embeddings = load_embeddings(embeddings_file_path)\n",
    "\n",
    "    X, y, embeddings = [], [], []\n",
    "\n",
    "    print(\"Embeddings shape:\", all_embeddings.shape)\n",
    "\n",
    "    # 각 이미지에 해당하는 바운딩 박스 딕셔너리를 추출하여 get_img 함수로 크로핑되고 같은 크기로 바뀐 이미지를 \n",
    "    for index, filename in enumerate(filenames):\n",
    "        bounding_box = bounding_boxes[filename]\n",
    "\n",
    "        try:\n",
    "            # Load images\n",
    "            img_name = '{0}/images/{1}'.format(cub_dataset_dir, filename)\n",
    "            img = get_img(img_name, bounding_box, image_size)\n",
    "            '''\n",
    "            all_embeddings1 = all_embeddings[index, :, :]\n",
    "\n",
    "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
    "            '''\n",
    "            embedding = all_embeddings[index, :]\n",
    "            # X = 정제한 이미지 리스트\n",
    "            X.append(np.array(img))\n",
    "            '''\n",
    "            # y = 정제한 이미지 인덱스\n",
    "            y.append(class_ids[index])\n",
    "            '''\n",
    "            # embeddings = \n",
    "            embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    embeddings = np.array(embeddings)\n",
    "    return X, embeddings\n",
    "\n",
    "\n",
    "def generate_c(x):\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "    stddev = K.exp(log_sigma)\n",
    "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n",
    "    c = stddev * epsilon + mean\n",
    "    return c\n",
    "\n",
    "\n",
    "def build_ca_model():\n",
    "    \"\"\"\n",
    "    (1024,)의 텍스트 인코더 신경망의 출력을 입력으로 받고 (256,) 의 텐서를 출력\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_embedding_compressor_model():\n",
    "    \"\"\"\n",
    "    입력 속성값 (40,) 을 (128,) 의 벡터로 확장하는 네트워크\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(40,))\n",
    "    x = Dense(10)(input_layer)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_stage1_generator():\n",
    "    \"\"\"\n",
    "    Stage-I 의 generator \n",
    "    *** 이 신경망 안에 CA 신경망과 생성기 신경망이 들어가 있다!!!! ***\n",
    "    그러므로, 입력으로 텍스트 임베딩 출력 (1024,)과 잡음 변수(100,) 을 받는다\n",
    "    \"\"\"\n",
    "    '''\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    c = Lambda(generate_c)(mean_logsigma)\n",
    "\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "    gen_input = Concatenate(axis=1)([c, input_layer2])\n",
    "    '''\n",
    "    # 텍스트 조건부 변수를 잡음 변수와 접합(concatenation) -> cGAN\n",
    "\n",
    "    input_layer = Input(shape=(40,))\n",
    "    x = Dense(10)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(input_layer)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
    "    x = Dropout(0.0)(x)\n",
    "    \n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = Activation(activation='tanh')(x)\n",
    "\n",
    "    stage1_gen = Model(inputs=input_layer, outputs=[x, mean_logsigma])\n",
    "    '''\n",
    "    stage - I gen 은 입력된 문장의 임베딩을 바탕으로 (+잡음 변수) 이미지를 생성 함 \n",
    "    '''\n",
    "    return stage1_gen\n",
    "\n",
    "\n",
    "def build_stage1_discriminator():\n",
    "    \"\"\"\n",
    "    Create a model which takes two inputs\n",
    "    1. One from above network\n",
    "    2. One from the embedding layer\n",
    "    3. Concatenate along the axis dimension and feed it to the last module which produces final logits\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "\n",
    "    x = Conv2D(64, (4, 4),\n",
    "               padding='same', strides=2,\n",
    "               input_shape=(64, 64, 3), use_bias=False)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    '''\n",
    "    실제 이미지에 해당하는 압축된 임베딩을 입력\n",
    "    '''\n",
    "    input_layer2 = Input(shape=(4, 4, 10))\n",
    "\n",
    "    '''\n",
    "    입력 이미지와 압축 텍스트 임베딩을 합침\n",
    "    '''\n",
    "    merged_input = concatenate([x, input_layer2])\n",
    "\n",
    "    x2 = Conv2D(64 * 8, kernel_size=1,\n",
    "                padding=\"same\", strides=1)(merged_input)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(1)(x2)\n",
    "    x2 = Activation('sigmoid')(x2)\n",
    "\n",
    "    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n",
    "    '''\n",
    "    출력은 입력 이미지가 진짜인지 가짜인지에 관한 확률(sigmoid)을 출력\n",
    "    '''\n",
    "    return stage1_dis\n",
    "\n",
    "\n",
    "def build_adversarial_model(gen_model, dis_model):\n",
    "    input_layer = Input(shape=(40,))\n",
    "    input_layer3 = Input(shape=(4, 4, 10))\n",
    "\n",
    "    x, mean_logsigma = gen_model(input_layer)\n",
    "\n",
    "    dis_model.trainable = False\n",
    "    valid = dis_model([x, input_layer3])\n",
    "\n",
    "    model = Model(inputs=[input_layer, input_layer3], outputs=[valid, mean_logsigma])\n",
    "    return model\n",
    "\n",
    "\n",
    "def KL_loss(y_true, y_pred):\n",
    "    mean = y_pred[:, :128]\n",
    "    logsigma = y_pred[:, :128]\n",
    "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def custom_generator_loss(y_true, y_pred):\n",
    "    # Calculate binary cross entropy loss\n",
    "    return K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "'''\n",
    "def save_rgb_img(img, path):\n",
    "    \"\"\"\n",
    "    Save an rgb image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "'''\n",
    "def save_rgb_img(img_gen, img_real, path):\n",
    "    \"\"\"\n",
    "    Save an rgb image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(img_gen)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image_gen\")\n",
    "    \n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(img_real)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image_real\")\n",
    "    \n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "def write_log(callback, name, loss, batch_no):\n",
    "    \"\"\"\n",
    "    Write training summary to TensorBoard\n",
    "    \"\"\"\n",
    "    with callback.as_default():\n",
    "          tf.summary.scalar(name, loss, batch_no)\n",
    "          callback.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Stage - I stackGAN 훈련\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    하이퍼파라미터(불변 파라미터) 지정\n",
    "    '''\n",
    "    data_dir = \"/home/csle/Desktop/CelebA_dataset_reduce_cropped\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    image_size = 64\n",
    "    batch_size = 128\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 1500\n",
    "    condition_dim = 10\n",
    "\n",
    "    embeddings_file_path_train = train_dir + \"/attr_(embeddings).pickle\"\n",
    "    embeddings_file_path_test = test_dir + \"/attr_(embeddings).pickle\"\n",
    "\n",
    "    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n",
    "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
    "\n",
    "    '''\n",
    "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
    "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
    "    '''\n",
    "\n",
    "    cub_dataset_dir = data_dir + \"/img_align_celeba\"\n",
    "\n",
    "    '''\n",
    "    optimizer 정의\n",
    "    '''\n",
    "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    \"\"\"\"\n",
    "    dataset 로드하기\n",
    "    \"\"\"\n",
    "    X_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n",
    "                                                      cub_dataset_dir=cub_dataset_dir,\n",
    "                                                      embeddings_file_path=embeddings_file_path_train,\n",
    "                                                      image_size=(64, 64))\n",
    "\n",
    "    X_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
    "                                                   cub_dataset_dir=cub_dataset_dir,\n",
    "                                                   embeddings_file_path=embeddings_file_path_test,\n",
    "                                                   image_size=(64, 64))\n",
    "    \n",
    "    print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "progressive-bahamas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Epoch is: 0\n",
      "Number of batches 111\n",
      "Batch:1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2530\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'args_0' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fa49479227d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# stage-I 의 gen 에서 텍스트 임베딩을 바탕으로 저 해상도 fake 이미지를 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# 이때, 두 stage 는 랜덤하게 생성한 텍스트 임베딩을 나머지 입력으로 받음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mfake_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage1_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# stage-I dis 에 들어갈 압축 텍스트 임베딩을 랜덤하게 생성한 텍스트 임베딩 기반으로 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1606\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4206\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4207\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4208\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4209\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         if x is not None)\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    407\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#with tf.device('/gpu:0'): \n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6 \n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "신경망 빌드 & compile\n",
    "\"\"\"\n",
    "\n",
    "ca_model = build_ca_model()\n",
    "ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "stage1_dis = build_stage1_discriminator()\n",
    "stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
    "\n",
    "stage1_gen = build_stage1_generator()\n",
    "stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
    "\n",
    "embedding_compressor_model = build_embedding_compressor_model()\n",
    "embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "'''\n",
    "stage-I GAN 빌드& 컴파일\n",
    "이때, stage-I 의 discriminator 는 훈련시키지 않고 stage-I generator 의 가중치만 업데이트\n",
    "'''\n",
    "adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)\n",
    "adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
    "                          optimizer=gen_optimizer, metrics=None)\n",
    "\n",
    "\"\"\"\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "tensorboard.set_model(stage1_gen)\n",
    "tensorboard.set_model(stage1_dis)\n",
    "'''\n",
    "tensorboard.set_model(ca_model)\n",
    "'''\n",
    "tensorboard.set_model(embedding_compressor_model)\n",
    "\"\"\"\n",
    "# Generate an array containing real and fake values\n",
    "# Apply label smoothing as well\n",
    "real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "'''\n",
    "매 epoch 마다 아래를 반복함\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    print(\"========================================\")\n",
    "    print(\"Epoch is:\", epoch)\n",
    "    print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n",
    "\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "\n",
    "    # Load data and train model\n",
    "    number_of_batches = int(X_train.shape[0] / batch_size)\n",
    "    for index in range(number_of_batches):\n",
    "        print(\"Batch:{}\".format(index+1))\n",
    "        '''\n",
    "        모델에 입력으로 들어갈 이미지와 텍스트 임베딩을 받아옴 (각 텍스트 임베딩은 각 이미지에 대응 됨)\n",
    "        '''\n",
    "        # 원래는 CA 의 출력이 stage-I 으로 들어가야 하지만 gen 안에 CA 가 있음\n",
    "        z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "        # 배치 사이즈만큼 훈련(실제) 이미지를 추출\n",
    "        image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "        # 추출한 이미지에 대응하는 임베딩을 추출\n",
    "        embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n",
    "        # 이미지들을 정규화하여 값을 작게 만듬\n",
    "        image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "        # stage-I 의 gen 에서 텍스트 임베딩을 바탕으로 저 해상도 fake 이미지를 생성\n",
    "        # 이때, 두 stage 는 랜덤하게 생성한 텍스트 임베딩을 나머지 입력으로 받음\n",
    "        fake_images, _ = stage1_gen.predict(embedding_batch, verbose=3)\n",
    "\n",
    "        # stage-I dis 에 들어갈 압축 텍스트 임베딩을 랜덤하게 생성한 텍스트 임베딩 기반으로 생성\n",
    "        compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n",
    "        compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n",
    "        compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "        '''\n",
    "        discriminator 에서 입력 이미지가 CNN 을 통과한 결과와 속성값 (40,) 을 concatenate 해 주기 위해서는,\n",
    "        속성값 (40,) 를 compressor 네트워크를 통해 (128,) 로 확장하고,\n",
    "        reshape, tile 함수를 이용해 CNN 결과 (4, 4, 512) 와 (4, 4, :) 부분을 맞추어 주어야 한다.\n",
    "        '''\n",
    "\n",
    "        \"\"\"\n",
    "        stage-I dis 를 훈련함\n",
    "        \"\"\"\n",
    "        # 실제 이미지와 압축 텍스트 임베딩을 입력으로 하고 모든 레이블을 1 (이미지가 진짜라는 의미) 로 하여,\n",
    "        # dis 가 실제 이미지를 잘 분류 하게끔 훈련\n",
    "        dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],\n",
    "                                                  np.reshape(real_labels, (batch_size, 1)))\n",
    "        # gen 이 생성한 가짜 이미지와 압축 텍스트 임베딩을 입력으로 하고 모든 레이블을 0 (이미지가 가짜라는 의미) 로 하여,\n",
    "        # dis 가 가짜 이미지를 잘 분류 하게끔 훈련\n",
    "        dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],\n",
    "                                                  np.reshape(fake_labels, (batch_size, 1)))\n",
    "        # 실제 이미지와 압축 텍스트 임베딩을 '어긋나게' 입력으로 하고 모든 레이블을 0 (이미지가 가짜라는 의미) 로 하여,\n",
    "        # dis 가 실제 이미지를 잘 분류 하게끔 훈련\n",
    "        dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\n",
    "                                                   np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
    "        dis_loss_wrong2 = stage1_dis.train_on_batch([image_batch[:(batch_size - 2)], compressed_embedding[2:]],\n",
    "                                                   np.reshape(fake_labels[2:], (batch_size-2, 1)))\n",
    "        \n",
    "        d_loss = 0.5*np.add(dis_loss_wrong2, 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake)))\n",
    "        \n",
    "        print(\"d_loss_real:{}\".format(dis_loss_real))\n",
    "        print(\"d_loss_fake:{}\".format(dis_loss_fake))\n",
    "        print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\n",
    "        print(\"d_loss_wrong2:{}\".format(dis_loss_wrong))\n",
    "        \n",
    "        print(\"d_loss:{}\".format(d_loss))\n",
    "\n",
    "        \"\"\"\n",
    "        stage-I GAN 을 훈련함\n",
    "        이때, stage-I 의 discriminator 는 훈련시키지 않고 stage-I generator 의 가중치만 업데이트\n",
    "        \"\"\"\n",
    "        g_loss = adversarial_model.train_on_batch([embedding_batch, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
    "        print(\"g_loss:{}\".format(g_loss))\n",
    "\n",
    "        dis_losses.append(d_loss)\n",
    "        gen_losses.append(g_loss)\n",
    "\n",
    "    \"\"\"\n",
    "    각 epoch 마다 Tensorboard 에 loss 의 전체 배치 평균값 저장\n",
    "    \"\"\"\n",
    "    writer = tf.summary.create_file_writer(\"logs/\".format(time.time()))\n",
    "    write_log(writer, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
    "    write_log(writer, 'generator_loss', np.mean(gen_losses[0]), epoch)\n",
    "    '''\n",
    "    tf.summary.scalar('discriminator_loss', np.mean(dis_losses), epoch)\n",
    "    tf.summary.scalar('generator_loss', np.mean(gen_losses[0]), epoch)\n",
    "\n",
    "    tf.summary.scalar('discriminator_loss', np.mean(dis_losses))\n",
    "    tf.summary.scalar('generator_loss', np.mean(gen_losses[0]))\n",
    "    summary_op = tf.summary.merge()\n",
    "    summary_writer = tf.summary.FileWriter(\"logs/\".format(time.time()))\n",
    "    '''    \n",
    "    # 매 두번의 epoch 마다 이미지 gen & 이미지 저장\n",
    "    if epoch % 2 == 0:\n",
    "        # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "        z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "        embedding_batch = embeddings_test[0:batch_size]\n",
    "        fake_images, _ = stage1_gen.predict_on_batch(embedding_batch)\n",
    "        fake_images = (fake_images*127.5) + 127.5\n",
    "        fake_images = fake_images.astype('int')\n",
    "        \n",
    "        # Save images\n",
    "        '''\n",
    "        for i, img in enumerate(fake_images[:5]):\n",
    "            save_rgb_img(img, \"results/gen_{}_{}.png\".format(epoch, i))\n",
    "        '''\n",
    "        \n",
    "        for i in range(5):\n",
    "            img_gen = fake_images[i]\n",
    "            img_real = X_test[i]\n",
    "            save_rgb_img(img_gen, img_real, \"results/gen_{}_{}.png\".format(epoch, i))\n",
    "\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        # Save models\n",
    "        stage1_gen.save_weights(\"weights/stage1_gen_epoch_{}.h5\".format(epoch))\n",
    "        stage1_dis.save_weights(\"weights/stage1_dis_epoch_{}.h5\".format(epoch))\n",
    "\n",
    "'''\n",
    "이제 훈련된 stage-I 의 generator 와 discriminator 을 얻음 (+ embedding_compressor) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-enhancement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
