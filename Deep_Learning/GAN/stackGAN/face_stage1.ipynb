{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras import Input, Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n",
    "    concatenate, Flatten, Lambda, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def load_class_ids(class_info_file_path):\n",
    "    \"\"\"\n",
    "    Load class ids from class_info.pickle file\n",
    "    \"\"\"\n",
    "    with open(class_info_file_path, 'rb') as f:\n",
    "        class_ids = pickle.load(f, encoding='latin1')\n",
    "        return class_ids\n",
    "\n",
    "\n",
    "def load_embeddings(embeddings_file_path):\n",
    "    \"\"\"\n",
    "    훈련된 텍스트 임베딩을 불러옴\n",
    "    \"\"\"\n",
    "    with open(embeddings_file_path, 'rb') as f:\n",
    "        embeddings = pickle.load(f, encoding='latin1')\n",
    "        embeddings = np.array(embeddings)\n",
    "        print('embeddings: ', embeddings.shape)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def load_filenames(filenames_file_path):\n",
    "    \"\"\"\n",
    "    Load filenames.pickle file and return a list of all file names\n",
    "    \"\"\"\n",
    "    with open(filenames_file_path, 'rb') as f:\n",
    "        filenames = pickle.load(f, encoding='latin1')\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def load_bounding_boxes(dataset_dir):\n",
    "    \"\"\"\n",
    "    이미지와 그에 상응하는 바운딩 박스를 짝지어 딕셔너리로 만들어 출력\n",
    "    \"\"\"\n",
    "    # 바운딩 박스 전체 경로\n",
    "    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n",
    "    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n",
    "\n",
    "    # bounding_boxes.txt 와 images.txt 파일을 읽어옴\n",
    "    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n",
    "                                    delim_whitespace=True, header=None).astype(int)\n",
    "    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n",
    "\n",
    "    # 전체 이미지 파일 명이 순서대로 적힌 리스트를 만듬\n",
    "    file_names = df_file_names[1].tolist()\n",
    "\n",
    "    # 파일 이름에 대응하는 바운딩 박스가 들어갈 딕셔너리를 만듬 (딕셔너리는 크기를 임의로 증가시킬수 있으므로 초기 사이즈는 아무렇게나)\n",
    "    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n",
    "\n",
    "    # 이미지 파일과 그에 해당하는 바운딩 박스를 딕셔너리로 만듬 (key = 이미지 파일 이름)\n",
    "    for i in range(0, len(file_names)):\n",
    "        # Get the bounding box\n",
    "        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n",
    "        key = file_names[i][:-4]\n",
    "        filename_boundingbox_dict[key] = bounding_box\n",
    "\n",
    "    return filename_boundingbox_dict\n",
    "\n",
    "'''\n",
    "새 이미지가 크롭핑 되어있지 않기 크롭하기 위한 바운딩 박스 좌표 값이 파일에 주어지며,\n",
    "그 파일을 토대로 이미지를 크로핑 한 후,\n",
    "크로핑된 모든 이미지를 지정한 이미지 크기 (image_size) 값으로 바꾼다\n",
    "'''\n",
    "def get_img(img_path, bbox, image_size):\n",
    "    \"\"\"\n",
    "    Load and resize image\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    if bbox is not None:\n",
    "        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
    "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
    "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
    "        y1 = np.maximum(0, center_y - R)\n",
    "        y2 = np.minimum(height, center_y + R)\n",
    "        x1 = np.maximum(0, center_x - R)\n",
    "        x2 = np.minimum(width, center_x + R)\n",
    "        img = img.crop([x1, y1, x2, y2])\n",
    "    img = img.resize(image_size, PIL.Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    filenames = load_filenames(filenames_file_path)\n",
    "    class_ids = load_class_ids(class_info_file_path)\n",
    "    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n",
    "    all_embeddings = load_embeddings(embeddings_file_path)\n",
    "\n",
    "    X, y, embeddings = [], [], []\n",
    "\n",
    "    print(\"Embeddings shape:\", all_embeddings.shape)\n",
    "    \n",
    "    # 각 이미지에 해당하는 바운딩 박스를 추출하여 get_img 함수로 크로핑되고 같은 크기로 바뀐 이미지를 \n",
    "    for index, filename in enumerate(filenames):\n",
    "        bounding_box = bounding_boxes[filename]\n",
    "\n",
    "        try:\n",
    "            # Load images\n",
    "            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n",
    "            img = get_img(img_name, bounding_box, image_size)\n",
    "\n",
    "            all_embeddings1 = all_embeddings[index, :, :]\n",
    "\n",
    "            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)\n",
    "            embedding = all_embeddings1[embedding_ix, :]\n",
    "            # X = 정제한 이미지 리스트\n",
    "            X.append(np.array(img))\n",
    "            # y = 정제한 이미지 인덱스\n",
    "            y.append(class_ids[index])\n",
    "            # embeddings = \n",
    "            embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    embeddings = np.array(embeddings)\n",
    "    return X, y, embeddings\n",
    "\n",
    "\n",
    "def generate_c(x):\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "    stddev = K.exp(log_sigma)\n",
    "    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))\n",
    "    c = stddev * epsilon + mean\n",
    "    return c\n",
    "\n",
    "\n",
    "def build_ca_model():\n",
    "    \"\"\"\n",
    "    (1024,)의 텍스트 인코더 신경망의 출력을 입력으로 받고 (256,) 의 텐서를 출력\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_embedding_compressor_model():\n",
    "    \"\"\"\n",
    "    Build embedding compressor model\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(128)(input_layer)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_stage1_generator():\n",
    "    \"\"\"\n",
    "    Stage-I 의 generator \n",
    "    *** 이 신경망 안에 CA 신경망과 생성기 신경망이 들어가 있다!!!! ***\n",
    "    그러므로, 입력으로 텍스트 임베딩 출력 (1024,)과 잡음 변수(100,) 을 받는다\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    x = Dense(256)(input_layer)\n",
    "    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    c = Lambda(generate_c)(mean_logsigma)\n",
    "\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "    '''\n",
    "    텍스트 조건부 변수를 잡음 변수와 접합(concatenation) -> cGAN\n",
    "    '''\n",
    "    gen_input = Concatenate(axis=1)([c, input_layer2])\n",
    "\n",
    "    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n",
    "    x = Activation(activation='tanh')(x)\n",
    "    \n",
    "    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n",
    "    '''\n",
    "    stage - I gen 은 입력된 문장의 임베딩을 바탕으로 (+잡음 변수) 이미지를 생성 함 \n",
    "    '''\n",
    "    return stage1_gen\n",
    "\n",
    "\n",
    "def build_stage1_discriminator():\n",
    "    \"\"\"\n",
    "    Create a model which takes two inputs\n",
    "    1. One from above network\n",
    "    2. One from the embedding layer\n",
    "    3. Concatenate along the axis dimension and feed it to the last module which produces final logits\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "\n",
    "    x = Conv2D(64, (4, 4),\n",
    "               padding='same', strides=2,\n",
    "               input_shape=(64, 64, 3), use_bias=False)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    '''\n",
    "    실제 이미지에 해당하는 압축된 임베딩을 입력\n",
    "    '''\n",
    "    input_layer2 = Input(shape=(4, 4, 128))\n",
    "    \n",
    "    '''\n",
    "    입력 이미지와 압축 텍스트 임베딩을 합침\n",
    "    '''\n",
    "    merged_input = concatenate([x, input_layer2])\n",
    "\n",
    "    x2 = Conv2D(64 * 8, kernel_size=1,\n",
    "                padding=\"same\", strides=1)(merged_input)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.2)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dense(1)(x2)\n",
    "    x2 = Activation('sigmoid')(x2)\n",
    "\n",
    "    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n",
    "    '''\n",
    "    출력은 입력 이미지가 진짜인지 가짜인지에 관한 확률(sigmoid)을 출력\n",
    "    '''\n",
    "    return stage1_dis\n",
    "\n",
    "\n",
    "def build_adversarial_model(gen_model, dis_model):\n",
    "    input_layer = Input(shape=(1024,))\n",
    "    input_layer2 = Input(shape=(100,))\n",
    "    input_layer3 = Input(shape=(4, 4, 128))\n",
    "\n",
    "    x, mean_logsigma = gen_model([input_layer, input_layer2])\n",
    "\n",
    "    dis_model.trainable = False\n",
    "    valid = dis_model([x, input_layer3])\n",
    "\n",
    "    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid, mean_logsigma])\n",
    "    return model\n",
    "\n",
    "\n",
    "def KL_loss(y_true, y_pred):\n",
    "    mean = y_pred[:, :128]\n",
    "    logsigma = y_pred[:, :128]\n",
    "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def custom_generator_loss(y_true, y_pred):\n",
    "    # Calculate binary cross entropy loss\n",
    "    return K.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "def save_rgb_img(img, path):\n",
    "    \"\"\"\n",
    "    Save an rgb image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def write_log(callback, name, loss, batch_no):\n",
    "    \"\"\"\n",
    "    Write training summary to TensorBoard\n",
    "    \"\"\"\n",
    "    summary = tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = loss\n",
    "    summary_value.tag = name\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "    callback.writer.flush()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Stage - I stackGAN 훈련\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    하이퍼파라미터(불변 파라미터) 지정\n",
    "    '''\n",
    "    data_dir = \"data/birds/\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    image_size = 64\n",
    "    batch_size = 64\n",
    "    z_dim = 100\n",
    "    stage1_generator_lr = 0.0002\n",
    "    stage1_discriminator_lr = 0.0002\n",
    "    stage1_lr_decay_step = 600\n",
    "    epochs = 1000\n",
    "    condition_dim = 128\n",
    "\n",
    "    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\n",
    "    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n",
    "    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n",
    "\n",
    "    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n",
    "    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n",
    "\n",
    "    cub_dataset_dir = data_dir + \"/CUB_200_2011\"\n",
    "    \n",
    "    '''\n",
    "    optimizer 정의\n",
    "    '''\n",
    "    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    \"\"\"\"\n",
    "    dataset 로드하기\n",
    "    \"\"\"\n",
    "    X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n",
    "                                                      class_info_file_path=class_info_file_path_train,\n",
    "                                                      cub_dataset_dir=cub_dataset_dir,\n",
    "                                                      embeddings_file_path=embeddings_file_path_train,\n",
    "                                                      image_size=(64, 64))\n",
    "\n",
    "    X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n",
    "                                                   class_info_file_path=class_info_file_path_test,\n",
    "                                                   cub_dataset_dir=cub_dataset_dir,\n",
    "                                                   embeddings_file_path=embeddings_file_path_test,\n",
    "                                                   image_size=(64, 64))\n",
    "\n",
    "    \"\"\"\n",
    "    신경망 빌드 & compile\n",
    "    \"\"\"\n",
    "    ca_model = build_ca_model()\n",
    "    ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "    stage1_dis = build_stage1_discriminator()\n",
    "    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
    "\n",
    "    stage1_gen = build_stage1_generator()\n",
    "    stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
    "\n",
    "    embedding_compressor_model = build_embedding_compressor_model()\n",
    "    embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "    \n",
    "    '''\n",
    "    stage-I GAN 빌드& 컴파일\n",
    "    이때, stage-I 의 discriminator 는 훈련시키지 않고 stage-I generator 의 가중치만 업데이트\n",
    "    '''\n",
    "    adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)\n",
    "    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
    "                              optimizer=gen_optimizer, metrics=None)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "    tensorboard.set_model(stage1_gen)\n",
    "    tensorboard.set_model(stage1_dis)\n",
    "    tensorboard.set_model(ca_model)\n",
    "    tensorboard.set_model(embedding_compressor_model)\n",
    "\n",
    "    # Generate an array containing real and fake values\n",
    "    # Apply label smoothing as well\n",
    "    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
    "    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
    "    '''\n",
    "    매 epoch 마다 아래를 반복함\n",
    "    '''\n",
    "    for epoch in range(epochs):\n",
    "        print(\"========================================\")\n",
    "        print(\"Epoch is:\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n",
    "\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "\n",
    "        # Load data and train model\n",
    "        number_of_batches = int(X_train.shape[0] / batch_size)\n",
    "        for index in range(number_of_batches):\n",
    "            print(\"Batch:{}\".format(index+1))\n",
    "            '''\n",
    "            모델에 입력으로 들어갈 이미지와 텍스트 임베딩을 받아옴 (각 텍스트 임베딩은 각 이미지에 대응 됨)\n",
    "            '''\n",
    "            # 원래는 CA 의 출력이 stage-I 으로 들어가야 하지만 gen 안에 CA 가 있음\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            # 배치 사이즈만큼 훈련(실제) 이미지를 추출\n",
    "            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "            # 추출한 이미지에 대응하는 임베딩을 추출\n",
    "            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n",
    "            # 이미지들을 정규화하여 값을 작게 만듬\n",
    "            image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "            # stage-I 의 gen 에서 텍스트 임베딩을 바탕으로 저 해상도 fake 이미지를 생성\n",
    "            # 이때, 두 stage 는 랜덤하게 생성한 텍스트 임베딩을 나머지 입력으로 받음\n",
    "            fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n",
    "\n",
    "            # stage-I dis 에 들어갈 압축 텍스트 임베딩을 랜덤하게 생성한 텍스트 임베딩 기반으로 생성\n",
    "            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n",
    "            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n",
    "            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "            \"\"\"\n",
    "            stage-I dis 를 훈련함\n",
    "            \"\"\"\n",
    "            # 실제 이미지와 압축 텍스트 임베딩을 입력으로 하고 모든 레이블을 1 (이미지가 진짜라는 의미) 로 하여,\n",
    "            # dis 가 실제 이미지를 잘 분류 하게끔 훈련\n",
    "            dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],\n",
    "                                                      np.reshape(real_labels, (batch_size, 1)))\n",
    "            # gen 이 생성한 가짜 이미지와 압축 텍스트 임베딩을 입력으로 하고 모든 레이블을 0 (이미지가 가짜라는 의미) 로 하여,\n",
    "            # dis 가 가짜 이미지를 잘 분류 하게끔 훈련\n",
    "            dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],\n",
    "                                                      np.reshape(fake_labels, (batch_size, 1)))\n",
    "            # 실제 이미지와 압축 텍스트 임베딩을 입력으로 하고 모든 레이블을 0 (이미지가 가짜라는 의미) 로 하여,\n",
    "            # dis 가 실제 이미지를 잘 분류 하게끔 훈련\n",
    "            dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\n",
    "                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
    "\n",
    "            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
    "\n",
    "            print(\"d_loss_real:{}\".format(dis_loss_real))\n",
    "            print(\"d_loss_fake:{}\".format(dis_loss_fake))\n",
    "            print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\n",
    "            print(\"d_loss:{}\".format(d_loss))\n",
    "\n",
    "            \"\"\"\n",
    "            stage-I GAN 을 훈련함\n",
    "            이때, stage-I 의 discriminator 는 훈련시키지 않고 stage-I generator 의 가중치만 업데이트\n",
    "            \"\"\"\n",
    "            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
    "            print(\"g_loss:{}\".format(g_loss))\n",
    "\n",
    "            dis_losses.append(d_loss)\n",
    "            gen_losses.append(g_loss)\n",
    "\n",
    "        \"\"\"\n",
    "        각 epoch 마다 Tensorboard 에 loss 저장\n",
    "        \"\"\"\n",
    "        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
    "        write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\n",
    "        \n",
    "        # 매 두번의 epoch 마다 이미지 gen & 이미지 저장\n",
    "        if epoch % 2 == 0:\n",
    "            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n",
    "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
    "            embedding_batch = embeddings_test[0:batch_size]\n",
    "            fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
    "\n",
    "            # Save images\n",
    "            for i, img in enumerate(fake_images[:10]):\n",
    "                save_rgb_img(img, \"results/gen_{}_{}.png\".format(epoch, i))\n",
    "\n",
    "    # Save models\n",
    "    stage1_gen.save_weights(\"stage1_gen.h5\")\n",
    "    stage1_dis.save_weights(\"stage1_dis.h5\")\n",
    "    \n",
    "    '''\n",
    "    이제 훈련된 stage-I 의 generator 와 discriminator 을 얻음 (+ embedding_compressor) \n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
