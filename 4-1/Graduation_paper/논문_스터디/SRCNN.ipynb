{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import *\n",
    "import torch\n",
    "import math\n",
    "from os.path import join\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from random import randrange\n",
    "from math import sqrt\n",
    "\n",
    "'''\n",
    "1. Normalization 과 Activation 을 포함한 Conv. Layer 모듈 생성 \n",
    "'''\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=1, bias=True, activation='prelu', norm=None):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n",
    "\n",
    "        self.norm = norm\n",
    "        if self.norm =='batch':\n",
    "            self.bn = torch.nn.BatchNorm2d(output_size)\n",
    "        elif self.norm == 'instance':\n",
    "            self.bn = torch.nn.InstanceNorm2d(output_size)\n",
    "        \n",
    "        # self.bn : Conv Layer 출력에서 normalization 을 Instance 로 할지 Batch 로 할지 선택\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            self.act = torch.nn.ReLU(True)\n",
    "        elif self.activation == 'prelu':\n",
    "            self.act = torch.nn.PReLU()\n",
    "        elif self.activation == 'lrelu':\n",
    "            self.act = torch.nn.LeakyReLU(0.2, True)\n",
    "        elif self.activation == 'tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.act = torch.nn.Sigmoid()\n",
    "        \n",
    "        # self.act : Conv Layer 출력 Activation Function 선택\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.norm is not None:\n",
    "            out = self.bn(self.conv(x))\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.act(out)\n",
    "        else:\n",
    "            return out\n",
    "    \n",
    "'''\n",
    "2. (1)에서 만든 ConvBlock() 을 사용하여 SRCNN 을 만듬\n",
    "    이때, 각 layer1, 2, 3 에서 weights 를 초기화\n",
    "'''\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels, base_filter, scale_factor):\n",
    "        super(SRCNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = ConvBlock(num_channels, base_filter, kernel_size=9, stride=1, padding=4, activation='relu', norm=None)\n",
    "        # 9x9 filter, stride=1, padding=4 conv layer, Activation Function = 'ReLU', Normalization 없음\n",
    "        self.layer2 = ConvBlock(base_filter, base_filter // 2, kernel_size=1, stride=1, padding=0, activation='relu', norm=None)\n",
    "        # 1x1 filter, stride=1, padding=0 conv layer, Activation Function = 'ReLU', Normalization 없음\n",
    "        self.layer3 = ConvBlock(base_filter // 2, 3, kernel_size=5, stride=1, padding=2, activation=None, norm=None)\n",
    "        # 5x5 filter, stride=1, padding=2 conv layer, Activation Function = 'ReLU', Normalization 없음\n",
    "        # 출력 channel 이 3인것은 color 이미지를 다루기 때문에\n",
    "        \n",
    "        '''\n",
    "        이미 class 안에 정의되어있는 self. 가 붙은 변수들을 불러오려면 아래와 같은 방식을 취해야 함\n",
    "        '''\n",
    "        for m in self.modules():\n",
    "        # 모듈 목록 (layer1, layer2, layer3) 불러오기 \n",
    "            classname = m.__class__.__name__\n",
    "            # 불러온 module 의 이름 \n",
    "            if classname.find('Conv2d') != -1:\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            # Conv2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n",
    "            elif classname.find('ConvTranspose2d') != -1:\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "           # ConvTranspose2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n",
    "        \n",
    "    def forward(self, x):\n",
    "        f1 = self.layer1(x)\n",
    "        f2 = self.layer2(f1)\n",
    "        y = self.layer3(f2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "'''\n",
    "3. Activation 을 포함한 Conv. Layer 모듈 생성, (1)과 달리 Activation 선택은 불가 \n",
    "'''\n",
    "class Conv_ReLU_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_ReLU_Block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "    \n",
    "'''\n",
    "4. filename 에 .png, .jpg, .jpeg 중 하나라도 있으면 True 를 반환하는 함수\n",
    "'''\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "'''\n",
    "5. PIL 을 이용하여 filepath에서 이미지를 불러오고 RGB 로 convert 하여 반환하는 함수\n",
    "'''\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('RGB')\n",
    "    return img\n",
    "'''\n",
    "6. PIL 을 이용하여 이미지를 Bicubic 으로 scale 만큼 High Resolution 으로 만드는 함수\n",
    "'''\n",
    "def rescale_img(img_in, scale):\n",
    "    size_in = img_in.size\n",
    "    # size_in = img_in 의 (width, height) tuple\n",
    "    new_size_in = tuple([int(x * scale) for x in size_in])\n",
    "    # new_size_in = (width * scale, height * scale)\n",
    "    img_in = img_in.resize(new_size_in, resample=Image.BICUBIC)\n",
    "    return img_in\n",
    "'''\n",
    "7. 원본이미지, downscale 이미지, upscale 이미지의 크기가 서로 다르므로 같은 크기로 crop 해 주는 함수 \n",
    "'''\n",
    "def get_patch(img_in, img_tar, img_bic, patch_size, scale, ix=-1, iy=-1):\n",
    "    (ih, iw) = img_in.size\n",
    "    (th, tw) = (scale * ih, scale * iw)\n",
    "\n",
    "    patch_mult = scale #if len(scale) > 1 else 1\n",
    "    tp = patch_mult * patch_size\n",
    "    ip = tp // scale\n",
    "\n",
    "    if ix == -1:\n",
    "        ix = random.randrange(0, iw - ip + 1)\n",
    "    if iy == -1:\n",
    "        iy = random.randrange(0, ih - ip + 1)\n",
    "\n",
    "    (tx, ty) = (scale * ix, scale * iy)\n",
    "\n",
    "    img_in = img_in.crop((iy,ix,iy + ip, ix + ip))\n",
    "    img_tar = img_tar.crop((ty,tx,ty + tp, tx + tp))\n",
    "    img_bic = img_bic.crop((ty,tx,ty + tp, tx + tp))\n",
    "                \n",
    "    info_patch = {\n",
    "        'ix': ix, 'iy': iy, 'ip': ip, 'tx': tx, 'ty': ty, 'tp': tp}\n",
    "    # info_patch 에는 어떤 크기로 crop 했는지에 대한 정보가 있음\n",
    "    return img_in, img_tar, img_bic, info_patch\n",
    "'''\n",
    "8. 이미지데이터 증강(augmentation)\n",
    "'''\n",
    "def augment(img_in, img_tar, img_bic, flip_h=True, rot=True):\n",
    "    info_aug = {'flip_h': False, 'flip_v': False, 'trans': False}\n",
    "    \n",
    "    if random.random() < 0.5 and flip_h:\n",
    "        img_in = ImageOps.flip(img_in)\n",
    "        img_tar = ImageOps.flip(img_tar)\n",
    "        img_bic = ImageOps.flip(img_bic)\n",
    "        info_aug['flip_h'] = True\n",
    "    # 50%의 확률로, flip_h = True 면 img_in, img_tar, img_bic 을 모두 flip\n",
    "\n",
    "    if rot:\n",
    "        if random.random() < 0.5:\n",
    "            img_in = ImageOps.mirror(img_in)\n",
    "            img_tar = ImageOps.mirror(img_tar)\n",
    "            img_bic = ImageOps.mirror(img_bic)\n",
    "            info_aug['flip_v'] = True\n",
    "        if random.random() < 0.5:\n",
    "            img_in = img_in.rotate(180)\n",
    "            img_tar = img_tar.rotate(180)\n",
    "            img_bic = img_bic.rotate(180)\n",
    "            info_aug['trans'] = True\n",
    "    # 50%의 확률로, rot = True 면 img_in, img_tar, img_bic 을 모두 mirror & 180도 rotate\n",
    "    \n",
    "    return img_in, img_tar, img_bic, info_aug\n",
    "    # info_aug = 출력된 이미지에 어떤 preprocessing 을 했는지 알려줌\n",
    "    \n",
    "'''\n",
    "9. PIL 이미지나 ndarray 이미지를 Tensor로 바꾸어주는 함수\n",
    "'''\n",
    "def transform():\n",
    "    return Compose([ToTensor(),])\n",
    "\n",
    "'''\n",
    "10.사용자 정의 data 로드 - Training Data \n",
    "'''        \n",
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, image_dir, patch_size, upscale_factor, data_augmentation, transform=None):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
    "        # self.image_filenames = image_dir 에 있는 모든 이미지의 경로 list\n",
    "        self.patch_size = patch_size\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.transform = transform\n",
    "        self.data_augmentation = data_augmentation\n",
    "    '''\n",
    "    def __getitem__(self, index) 에서는 index 번째 data를 return 하도록 코드를 짠다\n",
    "    '''\n",
    "    def __getitem__(self, index):\n",
    "        target = load_img(self.image_filenames[index])\n",
    "        # target = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지\n",
    "        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC) \n",
    "        # input = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지\n",
    "        bicubic = rescale_img(input, self.upscale_factor)\n",
    "        # bicubic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n",
    "        \n",
    "        input, target, bicubic, _ = get_patch(input,target,bicubic,self.patch_size, self.upscale_factor)\n",
    "        # 세 이미지를 같은 크기로 crop\n",
    "        \n",
    "        if self.data_augmentation:\n",
    "            input, target, bicubic, _ = augment(input, target, bicubic)\n",
    "        # data_augmentation = True 라면, 세 이미지를 augment 함수로 증강\n",
    "        \n",
    "        if self.transform:\n",
    "            input = self.transform(input)\n",
    "            bicubic = self.transform(bicubic)\n",
    "            target = self.transform(target)\n",
    "        # self.transform = True 라면, 세 이미지를 PIL image 에서 Tensor로 바꾸어 줌\n",
    "        return input, target, bicubic\n",
    "    '''\n",
    "    def __len__(self) 에서는 data의 len을 return 하도록 코드를 짠다\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "'''\n",
    "11.사용자 정의 data 로드 - Test Data (file 이름까지 사용자 정의 데이터화 시킴)\n",
    "'''\n",
    "class DatasetFromFolderEval(data.Dataset):\n",
    "    def __init__(self, lr_dir, upscale_factor, transform=None):\n",
    "        super(DatasetFromFolderEval, self).__init__()\n",
    "        self.image_filenames = [join(lr_dir, x) for x in listdir(lr_dir) if is_image_file(x)]\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = load_img(self.image_filenames[index])\n",
    "        _, file = os.path.split(self.image_filenames[index])\n",
    "        # file = 이미지 경로 list 에서 file 이름만 잘라 냄\n",
    "\n",
    "        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC)       \n",
    "        bicubic = rescale_img(input, self.upscale_factor)\n",
    "        \n",
    "        if self.transform:\n",
    "            input = self.transform(input)\n",
    "            bicubic = self.transform(bicubic)\n",
    "            target = self.transform(target)\n",
    "            \n",
    "        return input, bicubic, target, file\n",
    "        # file 이름까지 return\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "'''\n",
    "12. Training Data 불러오기\n",
    "'''\n",
    "def get_training_set(data_dir, hr, upscale_factor, patch_size, data_augmentation):\n",
    "    hr_dir = join(data_dir, hr)\n",
    "    return DatasetFromFolder(hr_dir,patch_size, upscale_factor, data_augmentation,\n",
    "                             transform=transform())\n",
    "'''\n",
    "13. Test Data 불러오기\n",
    "'''\n",
    "def get_eval_set(lr_dir, upscale_factor):\n",
    "    return DatasetFromFolderEval(lr_dir, upscale_factor,\n",
    "                             transform=transform())\n",
    "\n",
    "print('finish')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchSize': 32, 'lr': 0.001, 'upscale_factor': 2, 'patch_size': 64, 'feature_number': 32, 'start_epoch': 1, 'nEpochs': 200, 'snapshots': 20, 'data_dir': 'C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/data_800개/train/', 'hr_train_dataset': 'DIV2K_train_HR', 'model_type': 'SRCNN', 'save_folder': 'C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/weights/', 'pretrained_sr': 'C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/weights/SRCNN_epoch_59.pth', 'pretrained': False, 'data_augmentation': False, 'gpu_mode': True, 'threads': 0, 'gpus': 1}\n",
      "===> Loading datasets\n",
      "===> Building model  SRCNN\n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'ConvBlock' object has no attribute 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5aa2c9e1e7ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m '''\n\u001b[0;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'===> Building model '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSRCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupscale_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-3a0c1c316713>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_channels, base_filter, scale_factor)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSRCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;31m# 9x9 filter, stride=1, padding=4 conv layer, Activation Function = 'ReLU', Normalization 없음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_filter\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-3a0c1c316713>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_size, output_size, kernel_size, stride, padding, bias, activation, norm)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# self.bn : Conv Layer 출력에서 normalization 을 Instance 로 할지 Batch 로 할지 선택\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'prelu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'ConvBlock' object has no attribute 'activation'"
     ]
    }
   ],
   "source": [
    "# Training code\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "from math import log10\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pdb\n",
    "import socket\n",
    "import time\n",
    "import easydict\n",
    "\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "'''\n",
    "# colab 에서 필요한 코드 이므로 주석처리\n",
    "\n",
    "opt = easydict.EasyDict({ \n",
    "    \"batchSize\": 32,           # batch size - 한번에 training할 patch의 숫자\n",
    "    \"lr\": 1e-3,                # learning rate\n",
    "    \"upscale_factor\": 2,       # Upscale 정도 - 2배, 4배\n",
    "    \"patch_size\": 64,         # patch 크기\n",
    "    \"feature_number\": 32,     # SRCNN model에서 사용할 feature 숫자\n",
    "    \n",
    "    \"start_epoch\": 1,           \n",
    "    \"nEpochs\": 200,            # training 횟수\n",
    "    \"snapshots\": 20,           # weight 저장 주기\n",
    "   \n",
    "    \"data_dir\":\"C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/data_800개/train/\", # dataset 저장 위치\n",
    "    \"hr_train_dataset\": \"DIV2K_train_HR\", # training에 사용할 dataset 종류\n",
    "\n",
    "    \"model_type\": \"SRCNN\",         # 모델이름\n",
    "    \"save_folder\": \"C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/weights/\", # weight 저장 위치\n",
    "\n",
    "    \"pretrained_sr\": \"C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/weights/SRCNN_epoch_59.pth\",\n",
    "    \"pretrained\": False,\n",
    "    \"data_augmentation\": False,\n",
    "    \"gpu_mode\": True,\n",
    "    \"threads\": 0,\n",
    "    \"gpus\": 1\n",
    "    })\n",
    "'''\n",
    "1. GPU 설정 및 parameter print\n",
    "'''\n",
    "gpus_list = range(opt.gpus)\n",
    "cudnn.benchmark = True\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "'''\n",
    "2. Training Data 로드\n",
    "'''\n",
    "print('===> Loading datasets')\n",
    "train_set = get_training_set(opt.data_dir, opt.hr_train_dataset, opt.upscale_factor, opt.patch_size, opt.data_augmentation)\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\n",
    "\n",
    "'''\n",
    "3. SRCNN 빌드 (Loss Function 으로 MSE 가 아니라 L1 Loss 사용)\n",
    "'''\n",
    "print('===> Building model ', opt.model_type)\n",
    "model = SRCNN(num_channels=3, base_filter=opt.feature_number, scale_factor=opt.upscale_factor)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "'''\n",
    "4. GPU 사용 여부 및 pretrained model 사용 여부 설정\n",
    "'''\n",
    "if cuda:\n",
    "    model = model.cuda(gpus_list[0])\n",
    "    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n",
    "    criterion = criterion.cuda(gpus_list[0])\n",
    "if opt.pretrained:\n",
    "    model_name = os.path.join(opt.pretrained_sr)\n",
    "    checkpoint = torch.load(model_name)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    loss = checkpoint['loss']\n",
    "    opt.start_epoch = checkpoint['epoch']\n",
    "    print('Pre-trained SR model is loaded.')\n",
    "\n",
    "'''\n",
    "5. Optimizer 설정\n",
    "'''\n",
    "optimizer = optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "\n",
    "'''\n",
    "6. 각 epoch 에서 어떻게 연산할지 설정하고 중간마다 weights 저장\n",
    "'''\n",
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        _, target, bicubic = Variable(batch[0]), Variable(batch[1]), Variable(batch[2])\n",
    "        if cuda:\n",
    "            # input = input.cuda(gpus_list[0])\n",
    "            target = target.cuda(gpus_list[0])\n",
    "            bicubic = bicubic.cuda(gpus_list[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t0 = time.time()\n",
    "        prediction = model(bicubic)\n",
    "\n",
    "        loss = criterion(prediction, target)\n",
    "        t1 = time.time()\n",
    "        epoch_loss += loss.data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, iteration, len(training_data_loader), loss.data, (t1 - t0)))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
    "    if (epoch+1) % (opt.snapshots) == 0:\n",
    "      model_out_path = opt.save_folder+\"SRCNN_epoch_{}.pth\".format(epoch)\n",
    "      torch.save({'epoch' : epoch,\n",
    "              'model_state_dict' : model.state_dict(),\n",
    "                'loss' : loss.data}, model_out_path)\n",
    "      print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "\n",
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)\n",
    "    \n",
    "'''\n",
    "6. 훈련 시작\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(opt.start_epoch, opt.nEpochs + 1):\n",
    "        train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testBatchSize': 1, 'gpu_mode': True, 'threads': 1, 'gpus': 1, 'upscale_factor': 2, 'input_dir': 'C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/data_800개/test/', 'test_dataset': 'Set5', 'output': 'C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/Results/', 'model_type': 'SRCNN', 'model': 'C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/weights/SRCNN_epoch_19.pth'}\n",
      "===> Loading datasets\n",
      "===> Building model\n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'ConvBlock' object has no attribute 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-6b0bd151dae8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'===> Building model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSRCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupscale_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgpus_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-3a0c1c316713>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_channels, base_filter, scale_factor)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSRCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;31m# 9x9 filter, stride=1, padding=4 conv layer, Activation Function = 'ReLU', Normalization 없음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_filter\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-3a0c1c316713>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_size, output_size, kernel_size, stride, padding, bias, activation, norm)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# self.bn : Conv Layer 출력에서 normalization 을 Instance 로 할지 Batch 로 할지 선택\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'prelu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'ConvBlock' object has no attribute 'activation'"
     ]
    }
   ],
   "source": [
    "# Validation code\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import reduce\n",
    "from math import log10\n",
    "\n",
    "# from scipy.misc import imsave\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import cv2\n",
    "import easydict\n",
    "\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "'''\n",
    "# colab 에서 필요한 코드 이므로 주석처리\n",
    "\n",
    "opt = easydict.EasyDict({ \n",
    "    \"testBatchSize\": 1, \n",
    "    \"gpu_mode\": True,\n",
    "    \"threads\": 1,\n",
    "    \"gpus\": 1,\n",
    "    \"upscale_factor\": 2,\n",
    "\n",
    "    \"input_dir\":\"C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/data_800개/test/\",  # test dataset 불러올위치\n",
    "    \"test_dataset\": \"Set5\",                             # 사용할 test dataset\n",
    "    \"output\": \"C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/Results/\", # 결과영상 저장위치\n",
    "    \"model_type\": \"SRCNN\",\n",
    "    \"model\": \"C:/Users/user/Desktop/SRCNN-20210324T094341Z-001/SRCNN/weights/SRCNN_epoch_19.pth\"})  # test에 사용할 weight 불러올 위치\n",
    "\n",
    "\n",
    "gpus_list=range(opt.gpus)\n",
    "print(opt)\n",
    "\n",
    "cuda = opt.gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "\n",
    "\n",
    "print('===> Loading datasets')\n",
    "test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n",
    "testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n",
    "\n",
    "print('===> Building model')\n",
    "\n",
    "model = SRCNN(num_channels=3, base_filter=32, scale_factor=opt.upscale_factor)\n",
    "model = torch.nn.DataParallel(model, device_ids=gpus_list)\n",
    "\n",
    "checkpoint = torch.load(opt.model)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loss = checkpoint['loss']\n",
    "epoch = checkpoint['epoch']\n",
    "print('Pre-trained SR model is loaded.')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda(gpus_list[0])\n",
    "\n",
    "def eval():\n",
    "    avg_psnr = 0\n",
    "    psnr_sq = 0\n",
    "    model.eval()\n",
    "    for batch in testing_data_loader:\n",
    "        with torch.no_grad():\n",
    "            input, bicubic, target, name = Variable(batch[0]), Variable(batch[1]), Variable(batch[2]), batch[3]\n",
    "        if cuda:\n",
    "            input = input.cuda(gpus_list[0])\n",
    "            bicubic = bicubic.cuda(gpus_list[0])\n",
    "            target = target.cuda(gpus_list[0])\n",
    "\n",
    "        prediction = model(bicubic)\n",
    "        mse = criterion(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.item())\n",
    "        avg_psnr += psnr\n",
    "        psnr_sq += psnr*psnr\n",
    "\n",
    "        save_img(prediction.cpu().data, name[0])\n",
    "        # save_img(bicubic.cpu().data, name[0])\n",
    "        # save_img(target.cpu().data, name[0])\n",
    "        average = avg_psnr/len(testing_data_loader)\n",
    "        variance = psnr_sq/len(testing_data_loader)-average*average\n",
    "    print(\"===> epoch number : %d\" % (epoch))     \n",
    "    print(\"===> Processing Done, Average PSNR : %.4f\" % (average))\n",
    "    print(\"===>PSNR Variance : %.4f\" % (variance))\n",
    "def save_img(img, img_name):\n",
    "    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    # save img\n",
    "    save_dir=os.path.join(opt.output,opt.test_dataset)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    save_fn = save_dir +'/'+ img_name\n",
    "    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    \n",
    "##Eval Start!!!!\n",
    "if __name__ == '__main__':\n",
    "    eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
